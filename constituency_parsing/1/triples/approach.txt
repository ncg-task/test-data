(Contribution||has||Approach)
(Approach||introducing||cloze - style training objective)
(cloze - style training objective||where||model)
(model||predict||center word)
(center word||given||left - to - right and right - to - left context representations)
(Approach||show||even larger performance gains)
(even larger performance gains||by||jointly pretraining)
(jointly pretraining||has||both directions)
(both directions||of||large language - model - inspired self - attention cloze model)
(even larger performance gains||has||possible)
(Approach||has||Our bi-directional transformer architecture)
(Our bi-directional transformer architecture||predicts||every token)
(every token||in||training data)
(Approach||has||Our model)
(Our model||separately computes||both forward and backward states)
(both forward and backward states||with||Equal contribution)
