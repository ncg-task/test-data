16	19	28	introduce
16	31	37	parser
16	43	51	combines
16	55	62	encoder
16	63	74	built using
16	88	117	self - attentive architecture
16	118	122	with
16	125	132	decoder
16	133	147	customized for
16	148	155	parsing
24	8	15	present
24	16	38	a version of our model
24	44	48	uses
24	51	65	character LSTM
24	74	82	performs
24	83	89	better
24	90	94	than
24	95	128	other lexical representationseven
24	129	131	if
24	132	147	word embeddings
24	152	159	removed
164	0	15	English ( WSJ )
168	4	14	test score
168	15	17	of
168	18	26	93.55 F1
168	27	30	for
168	35	50	CharLSTM parser
168	51	58	exceeds
168	63	84	previous best numbers
168	85	88	for
168	89	112	single - system parsers
168	113	123	trained on
168	128	141	Penn Treebank
169	5	15	our parser
169	19	33	augmented with
169	34	59	ELMo word representations
169	65	73	achieves
169	76	108	new state - of - the - art score
169	109	111	of
169	112	120	95.13 F1
169	121	123	on
169	128	140	WSJ test set
171	0	22	Multilingual ( SPMRL )
178	0	23	Development set results
178	24	28	show
178	38	46	addition
178	47	49	of
178	50	65	word embeddings
178	66	68	to
178	71	76	model
178	82	86	uses
178	89	103	character LSTM
178	110	122	mixed effect
178	128	136	improves
178	137	148	performance
178	149	152	for
178	153	167	some languages
178	174	179	hurts
178	180	183	for
178	184	190	others
180	0	2	On
180	3	23	8 of the 9 languages
180	26	45	our test set result
180	46	53	exceeds
180	58	91	previous best - published numbers
2	0	20	Constituency Parsing
163	2	9	Results
