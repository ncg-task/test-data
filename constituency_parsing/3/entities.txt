21	123	134	constructed
21	135	156	an artificial dataset
21	157	169	by labelling
21	172	184	large corpus
21	185	189	with
21	194	208	BerkeleyParser
26	27	52	second artificial dataset
26	53	66	consisting of
26	67	101	only high - confidence parse trees
26	107	118	measured by
26	123	132	agreement
26	133	135	of
26	136	147	two parsers
27	3	10	trained
27	13	43	sequence - to - sequence model
27	44	48	with
27	49	58	attention
25	3	10	trained
25	13	43	sequence - to - sequence model
25	44	48	with
25	49	58	attention
25	59	61	on
25	66	105	small human - annotated parsing dataset
67	22	26	used
67	29	34	model
67	35	39	with
67	40	53	3 LSTM layers
67	58	67	256 units
67	68	70	in
67	71	81	each layer
67	93	97	call
67	98	106	LSTM + A
70	0	11	Training on
70	14	27	small dataset
70	31	48	additionally used
70	49	65	2 dropout layers
70	72	79	between
70	80	97	LSTM 1 and LSTM 2
70	116	133	LSTM 2 and LSTM 3
82	4	19	embedding layer
82	20	23	for
82	24	42	our 90K vocabulary
82	50	61	initialized
82	62	70	randomly
82	74	79	using
82	80	116	pre-trained word - vector embeddings
83	3	14	pre-trained
83	15	37	skip - gram embeddings
83	38	40	of
83	41	49	size 512
83	50	55	using
83	56	64	word2vec
83	71	73	on
83	76	93	10B - word corpus
118	6	28	single attention model
118	29	36	gets to
118	37	41	88.3
118	49	80	ensemble of 5 LSTM + A+D models
118	81	89	achieves
118	90	94	90.5
118	95	103	matching
118	106	135	single - model BerkeleyParser
118	136	138	on
118	139	142	WSJ
120	3	31	ensemble of 5 LSTM+ A models
120	32	48	further improves
120	54	59	score
120	60	62	to
120	63	67	92.8
122	4	18	LSTM + A model
122	19	29	trained on
122	30	41	WSJ dataset
122	47	55	produced
122	56	71	malformed trees
122	72	75	for
122	76	78	25
122	79	81	of
122	86	100	1700 sentences
122	101	103	in
122	104	146	our development set ( 1.5 % of all cases )
122	174	204	full high - confidence dataset
122	214	217	for
122	218	240	14 sentences ( 0.8 % )
130	4	14	difference
130	15	22	between
130	27	36	F 1 score
130	37	39	on
130	40	49	sentences
130	50	52	of
130	53	59	length
130	60	84	upto 30 and that upto 70
130	88	91	1.3
130	92	95	for
130	100	114	BerkeleyParser
130	117	120	1.7
130	121	124	for
130	129	142	baseline LSTM
130	149	152	0.7
130	153	156	for
130	157	165	LSTM + A
157	0	8	LSTM + A
157	9	19	trained on
157	24	48	high - confidence corpus
157	88	96	achieved
157	100	109	F 1 score
157	110	112	of
157	113	117	95.7
157	57	59	on
157	121	124	QTB
157	129	133	84.6
157	118	120	on
157	137	140	WEB
119	5	15	trained on
119	20	50	large high - confidence corpus
119	55	76	single LSTM + A model
119	77	85	achieves
119	86	90	92.5
119	98	109	outperforms
119	123	140	best single model
119	156	176	best ensemble result
4	0	30	Syntactic constituency parsing
