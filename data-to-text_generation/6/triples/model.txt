(Contribution||has||Model)
(Model||consists in||exchange)
(exchange||of||encoder and decoder RNNs)
(Model||does not require||delexicalization)
(Model||does not require||tokenization)
(Model||does not require||lowercasing)
(Model||produces||vocabulary - free model)
(vocabulary - free model||does not depend on||specific domain 's set of terms)
(vocabulary - free model||has||inherently more general)
(vocabulary - free model||on||general alphabet)
(Model||has||peculiar training procedure)
(peculiar training procedure||enhancing||recall)
(peculiar training procedure||has||improves)
(improves||has||internal representation capabilities)
(Model||has||character - wise copy mechanism)
(character - wise copy mechanism||consisting in||soft switch)
(soft switch||between||generation and copy mode)
(Model||present||character - level sequence - to - sequence model)
(character - level sequence - to - sequence model||with||attention mechanism)
(character - level sequence - to - sequence model||results in||completely neural end - to - end architecture)
