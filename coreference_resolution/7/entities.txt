18	33	41	provides
18	45	74	entity - level representation
18	80	107	simple and intuitive manner
18	119	130	facilitates
18	131	158	end - to - end optimization
19	0	36	Our " Entity Equalization " approach
19	37	43	posits
19	49	60	each entity
19	71	86	represented via
19	91	94	sum
19	95	97	of
19	102	139	corresponding mention representations
22	52	56	uses
22	57	78	contextual embeddings
22	79	81	as
22	82	111	input mention representations
23	66	69	use
23	70	85	BERT embeddings
25	33	38	using
25	39	43	BERT
25	44	46	in
25	49	75	fully convolutional manner
119	4	12	baseline
119	20	40	span - ranking model
119	46	50	with
119	51	70	ELMo input features
119	75	110	second - order span representations
119	119	127	achieves
119	128	138	73.0 % Avg
120	5	14	Replacing
120	19	32	ELMo features
120	33	37	with
120	38	51	BERT features
120	52	60	achieves
120	61	80	76. 25 % average F1
122	10	42	secondorder span representations
122	43	47	with
122	48	67	Entity Equalization
122	68	76	achieves
122	77	96	76. 64 % average F1
121	0	8	Removing
121	13	50	second - order span - representations
121	51	62	while using
121	63	76	BERT features
121	77	85	achieves
121	86	96	76.37 % F1
123	12	15	set
123	18	38	new state of the art
123	39	42	for
123	43	65	coreference resolution
123	68	77	improving
123	82	107	previous state of the art
123	108	110	by
123	111	127	3.6 % average F1
2	0	22	Coreference Resolution
115	0	7	Results
