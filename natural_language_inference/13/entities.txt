13	3	10	propose
13	13	63	deep , end - to - end , neural comprehension model
13	72	76	call
13	81	90	EpiReader
26	14	26	factors into
26	27	41	two components
27	4	19	first component
27	20	28	extracts
27	31	61	small set of potential answers
27	62	70	based on
27	73	91	shallow comparison
27	92	94	of
27	99	132	question with its supporting text
27	138	142	call
27	152	161	Extractor
28	4	20	second component
28	21	28	reranks
28	33	49	proposed answers
28	50	58	based on
28	59	86	deeper semantic comparisons
28	87	91	with
28	96	100	text
28	106	110	call
28	120	128	Reasoner
32	4	24	semantic comparisons
32	25	39	implemented by
32	44	52	Reasoner
32	57	65	based on
32	70	77	concept
32	78	80	of
32	81	119	recognizing textual entailment ( RTE )
32	127	135	known as
32	136	162	natural language inference
34	11	20	Extractor
34	21	27	serves
34	32	50	important function
34	51	53	of
34	54	63	filtering
34	66	96	large set of potential answers
34	97	104	down to
34	107	128	small , tractable set
34	129	131	of
34	132	149	likely candidates
34	150	153	for
34	154	175	more thorough testing
35	14	21	follows
35	26	30	form
35	31	33	of
35	36	51	pointer network
35	58	62	uses
35	65	99	differentiable attention mechanism
35	100	111	to indicate
35	112	117	words
35	118	120	in
35	125	129	text
35	135	153	potentially answer
35	158	166	question
37	14	21	outputs
37	24	33	small set
37	34	36	of
37	37	54	answer candidates
37	55	65	along with
37	72	95	estimated probabilities
37	96	98	of
37	99	110	correctness
38	4	12	Reasoner
38	13	18	forms
38	19	29	hypotheses
38	30	42	by inserting
38	47	64	candidate answers
38	65	69	into
38	74	82	question
38	90	99	estimates
38	104	115	concordance
38	116	118	of
38	119	134	each hypothesis
38	135	139	with
38	140	153	each sentence
38	154	156	in
38	161	176	supporting text
36	18	42	used ( on it s own ) for
36	43	61	question answering
36	62	66	with
36	71	91	Attention Sum Reader
39	3	6	use
39	7	22	these estimates
39	23	25	as
39	28	35	measure
39	36	38	of
39	43	51	evidence
39	52	55	for
39	58	68	hypothesis
39	75	84	aggregate
39	85	93	evidence
39	94	101	overall
39	102	111	sentences
40	16	23	combine
40	28	48	Reasoner 's evidence
40	49	53	with
40	58	92	Extractor 's probability estimates
40	93	103	to produce
40	106	119	final ranking
40	120	122	of
40	127	144	answer candidates
221	3	8	train
221	9	18	our model
221	22	26	used
221	27	54	stochastic gradient descent
221	55	59	with
221	64	103	ADAM optimizer ( Kingma and Ba , 2014 )
221	114	135	initial learning rate
221	136	138	of
221	139	144	0.001
222	4	19	word embeddings
222	25	36	initialized
222	37	45	randomly
222	48	60	drawing from
222	65	85	uniform distribution
224	4	9	model
224	14	26	implement in
224	27	33	Theano
224	34	39	using
224	44	59	Keras framework
229	0	14	All our models
229	15	19	used
229	24	38	regularization
229	39	41	at
229	42	71	0.001 , ? = 50 , and ? = 0.04
223	3	7	used
223	8	15	batches
223	16	18	of
223	19	30	32 examples
223	37	51	early stopping
223	52	56	with
223	59	67	patience
223	68	70	of
223	71	79	2 epochs
2	0	30	Natural Language Comprehension
4	45	74	machine comprehension of text
5	0	57	Machine comprehension of unstructured , real - world text
6	17	38	machine comprehension
236	4	13	EpiReader
236	14	22	achieves
236	23	57	state - of - the - art performance
236	58	64	across
236	69	74	board
236	75	78	for
236	79	92	both datasets
243	4	15	improvement
243	16	18	on
243	19	27	CBT - NE
243	31	42	more modest
243	43	45	at
243	46	51	1.1 %
237	0	2	On
237	3	6	CNN
237	12	17	score
237	18	30	2.2 % higher
237	31	33	on
237	34	38	test
242	3	11	CBT - CN
242	12	28	our single model
242	29	35	scores
242	36	48	4.0 % higher
242	49	53	than
242	58	71	previous best
242	72	74	of
242	79	88	AS Reader
244	0	7	Looking
244	8	20	more closely
244	21	23	at
244	24	44	our CBT - NE results
244	50	60	found that
244	65	95	validation and test accuracies
244	100	124	relatively high variance
244	130	132	in
244	133	144	late epochs
244	145	147	of
244	148	156	training
