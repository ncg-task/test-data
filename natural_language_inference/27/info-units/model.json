{
  "has" : {
    "Model" : {
      "propose" : {
        "SDNet" : {
          "has" : {
            "contextual attention - based deep neural network" : {
              "for" : {
                "task" : {
                  "of" : "conversational question answering"
                }
              },
              "from sentence" : "In this paper , we propose SDNet , a contextual attention - based deep neural network for the task of conversational question answering ."
            }
          }
        }
      },
      "apply" : {
        "both inter-attention and self - attention" : {
          "on" : "passage and question",
          "to obtain" : {
            "more effective understanding" : {
              "of" : "passage and dialogue history"
            }
          },
          "from sentence" : "Firstly , we apply both inter-attention and self - attention on passage and question to obtain a more effective understanding of the passage and dialogue history ."
        }
      },
      "has" : {
        "SDNet" : {
          "leverages" : {
            "latest breakthrough" : {
              "in" : "NLP",
              "has" : "BERT contextual embedding"
            },
            "from sentence" : "Secondly , SDNet leverages the latest breakthrough in NLP : BERT contextual embedding ."
          }
        }
      },
      "employed" : {
        "weighted sum" : {
          "of" : {
            "BERT layer outputs" : {
              "with" : "locked BERT parameters"
            }
          },
          "from sentence" : "Different from the canonical way of appending a thin layer after BERT structure according to , we innovatively employed a weighted sum of BERT layer outputs , with locked BERT parameters ."
        }
      },
      "prepend" : {
        "previous rounds" : {
          "of" : "questions and answers",
          "to" : {
            "current question" : {
              "to incorporate" : "contextual information"
            }
          },
          "from sentence" : "Thirdly , we prepend previous rounds of questions and answers to the current question to incorporate contextual information ."
        }
      }
    }
  }
}