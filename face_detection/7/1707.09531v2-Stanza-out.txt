title
Recurrent Scale Approximation for Object Detection in CNN
abstract
Since convolutional neural network ( CNN ) lacks an inherent mechanism to handle large scale variations , we always need to compute feature maps multiple times for multiscale object detection , which has the bottleneck of computational cost in practice .
To address this , we devise a recurrent scale approximation ( RSA ) to compute feature map once only , and only through this map can we approximate the rest maps on other levels .
At the core of RSA is the recursive rolling out mechanism : given an initial map at a particular scale , it generates the prediction at a smaller scale that is half the size of input .
To further increase efficiency and accuracy , we ( a ) : design a scale - forecast network to globally predict potential scales in the image since there is no need to compute maps on all levels of the pyramid .
( b ) : propose a landmark retracing network ( LRN ) to trace back locations of the regressed landmarks and generate a confidence score for each landmark ; LRN can effectively alleviate false positives caused by the accumulated error in RSA .
The whole system can be trained end - to - end in a unified CNN framework .
Experiments demonstrate that our proposed algorithm is superior against state - of - the - art methods on face detection benchmarks and achieves comparable results for generic proposal generation .
The source code of our system is available .
1 .
Introduction
Object detection is one of the most important tasks in computer vision .
The convolutional neural network ( CNN ) based approaches have been widely applied in object detection and recognition with promising performance .
To localize objects at arbitrary scales and locations in an image , we need to han -
Our codes and annotations mentioned in Sec.4.1 can be accessed at github.com/sciencefans/RSA-for-object-detection dle the variations caused by appearance , location and scale .
Most of the appearance variations can now be handled in CNN , benefiting from the invariance property of convolution and pooling operations .
The location variations can be naturally solved via sliding windows , which can be efficiently incorporated into CNN in a fully convolutional manner .
However , CNN itself does not have an inherent mechanism to handle the scale variations .
The scale problem is often addressed via two ways , namely , multi-shot by single - scale detector and single - shot by multi-scale detector .
The first way , as shown in , handles objects of different scales independently by resizing the input into different scales and then forwarding the resized images multiple times for detection .
Models in such a philosophy probably have the highest recall as long as the sampling of scales is dense enough , but they suffer from high computation cost and more false positives .
The second way , as depicted in , forwards the image only once and then directly regresses objects at multiple scales .
Such a scheme takes the scale variation as a black box .
Although more parameters and complex structures would improve the performance , the spirit of direct regression still has limitations in real - time applications , for example in face detection , the size of faces can vary from 20 20 to 1920 1080 .
To handle the scale variation in a CNN - based detection system in terms of both efficiency and accuracy , we are inspired by the fast feature pyramid work proposed by Dollr et al. , where a detection system using hand - crafted features is designed for pedestrian detection .
It is found that image gradients across scales can be predicted based on natural image statistics .
They showed that dense feature pyramids can be efficiently constructed on top of coarsely sampled feature pyramids .
In this paper , we extend the spirit of fast feature pyramid to CNN and go a few steps further .
Our solution to the feature pyramid in CNN descends from the observations of modern CNN - based detectors , including Faster - RCNN , R - FCN , SSD , YOLO and STN , where feature maps are first computed and the detection results are decoded from the maps afterwards .
However , the computation cost of generating feature maps becomes a bottleneck for methods using multi-scale testing and it seems not to be a neat solution to the scale variation problem .
To this end , our philosophy of designing an elegant detection system is that we calculate the feature pyramid once only , and only through that pyramid can we approximate the rest feature pyramids at other scales .
The intuition is illustrated in .
In this work , we propose a recurrent scale approximation ( RSA , see ) unit to achieve the goal aforementioned .
The RSA unit is designed to be plugged at some specific depths in a network and to be fed with an initial feature map at the largest scale .
The unit convolves the input in a recurrent manner to generate the prediction of the feature map that is half the size of the input .
Such a scheme could feed the network with input at one scale only and approximate the rest features at smaller scales through a learnable RSA unit - a balance considering both efficiency and accuracy .
We propose two more schemes to further save the computational budget and improve the detection performance under the RSA framework .
The first is a scale - forecast network to globally predict potential scales for a novel image and we compute feature pyramids for just a certain set of scales based on the prediction .
There are only a few scales of objects appearing in the image and hence most of the feature pyramids correspond to the background , indicating a redundancy if maps on all levels are computed .
The second is a landmark retracing network that retraces the location of the regressed landmarks in the preceding layers and generates a confidence score for each landmark based on the landmark feature set .
The final score of identifying a face within an anchor is thereby revised by the LRN network .
Such a design alleviates false positives caused by the accumulated error in the RSA unit .
The pipeline of our proposed algorithm is shown in .
The three components can be incorporated into a unified CNN framework and trained end - to - end .
Experiments show that our approach is superior to other state - of the - art methods in face detection and achieves reasonable results for object detection .
To sum up , our contributions in this work are as follows :
1 ) We prove that deep CNN features for an image can be approximated from different scales using a portable recurrent unit ( RSA ) , which fully leverages efficiency and accuracy .
2 ) We propose a scale - forecast network to predict valid scales of the input , which further accelerates the detection pipeline .
3 ) We devise a landmark retracing network to enhance the accuracy in face detection by utilizing landmark information .
Related work
Multi - shot by single - scale detector .
A single - scale detector detects the target at atypical scale and can not handle features at other scales .
An image pyramid is thus formulated and each level in the pyramid is fed into the detector .
Such a framework appeared in pre-deep - learning era and usually involves hand - crafted features , e.g. , HOG or SIFT , and some classifier like Adaboost , to verify whether the context at each scale contains a target object .
Recently , some CNN - based methods also employ such a spirit to predict the objectness and class within a sliding window at each scale .
In this way , the detector only handles features in a certain range of scales and the variance is taken over by the image pyramid , which could reduce the fitting difficulty for detector but potentially increase the computational cost .
Single - shot by multi-scale detector .
A multi-scale detector takes one shot for the image and generates detection results aross all scales .
RPN and YOLO have fixed size of the input scale , and proposals for all scales are generated in the final layer by using multiple classifiers .
However , it is not easy to detect objects in various scales based on the final feature map .
Liu et al .
resolved the problem via a multi - level combination of predictions from feature maps on different scales .
And yet it still needs a large model for large receptive field for detection .
Other works proposed to merge deep and shallow features in a conv / deconv structure and to merge boxes for objects from different scales .
These methods are usually faster than the single - scale detector since it only takes one shot for image , but the large - scale invariance has to be learned by an expensive feature classifier , which is unstable and heavy .
Face detection .
Recent years have witnessed a performance boost in face detection , which takes advantage of the development in fully convolutional network .
Multi - task RPN is applied to generate face confidence and landmarks together .
Both single - scale and multi-scale strategies are introduced in these methods .
For example , Chen et . al propose a supervised spatial transform layer to utilize landmark information and thus enhance the quality of detector by a large margin .
Our Algorithm
In this section , we depict each component of our pipeline ) in detail .
We first devise a scale - forecast network to predict potential scales of the input ; the RSA unit is proposed to learn and predict features at smaller scales based on the output of the scale - forecast network ; the image is fed into the landmark retracing network to detect faces of various sizes , using the scale prediction in Section 3.1 and approximation in Section 3.2 .
The landmark retracing network stated in Section 3.3 can trace back features of regressed landmarks and generate individual confidence of each landmark to revise the final score of detecting a face .
At last , we discuss the superiority of our algorithm 's design over other alternatives in Section 3.4 .
Scale - forecast Network
We propose a scale - forecast network ( see ( a ) ) to predict the possible scales of faces given an input image of fixed size .
The network is a half - channel version of ResNet - 18 with a global pooling at the end .
The output of this network is a probability vector of B dimensions , where B = 60 is the predefined number of scales .
Let B = { 0 , 1 , , B} denote the scale set , we define the mapping from a face size x , in the context of an image being resized to a higher dimension 2048 , to the index bin B as :
For example , if the face has size of 64 , it s corresponding bin index b = 10 2 .
Prior to being fed into the network , an image is first resized with the higher dimension equal to 224 .
During training , the loss of our scale - forecast network is a binary multi-class cross entropy loss :
where p b , p bare the ground truth label and prediction of the b - th scale , respectively .
Note that the ground truth label for the neighbouring scales bi of an occurring scale b * ( p b * = 1 ) is not zero and is defined as the Gaussian sampling score :
where , ? are hyperparameters in the Gaussian distribution and N ( ) denotes the neighbour set .
Here we use 2 as the neighbour size and set , ? to b * , 1 / ?
2 ? , respectively .
Such a practice could alleviate the difficulty of feature learning in the discrete distribution between occurring scales ( 1 ) and non-occurring scales ( 0 ) .
For inference , we use the Gaussian mixture model to determine the local maximum and hence the potential occurring scales .
Given observations x , the distribution , parameterized by ? , can be decomposed into K mixture components :
where the i - th component is characterized by Gaussian distributions with weights ?
i , means i and covariance matrices ?
i .
Here K = { 1 , ... , 6 } denotes selected scale numbers of six main scales from 2 5 to 2 11 and the scale selection is determined by the threshold ?
i of each component .
Finally the best fitting model with a specific K is used .
Recurrent Scale Approximation ( RSA ) Unit
The recurrent scale approximation ( RSA ) unit is devised to predict feature maps at smaller scales given a map at the largest scale .
depicts the RSA unit .
The network architecture follows a build - up similar to the residual network , where we reduce the number of channels in each convolutional layer to half of the original version for time efficiency .
The structure details are shown in Section 4.1 .
Given an input image I , I m denotes the downsampled result of the image with a ratio of 1 / 2 m , where m ?
{ 0 , , M } is the downsample level and M =
5 . Note that I 0 is the original image .
Therefore , there are six scales in total , corresponding to the six main scale ranges defined in the scale - forecast network ( see Section 3.1 ) .
Given an input image I m , we define the output feature map of layer res2b as :
where f ( ) stands for a set of convolutions with a total stride of 8 from the input image to the output map .
The set of feature maps G mat different scales serves as the ground truth supervision of the recurrent unit .
The RSA module RSA ( ) takes as input the feature map of the largest scale G 0 at first , and repeatedly outputs a map with half the size of the input map :
where
Fm is the resultant map after being rolled out m times and w represents the weights in the RSA unit .
The RSA module has four convolutions with a total stride of 2 ( 1 , 2 , 1 , 1 ) and their kernal sizes are ( 1 ,3 , 3 , 1 ) .
The loss is therefore the l 2 norm between prediction Fm and supervision G m across all scales :
The gradients in the RSA unit are computed as :
where x and y are spatial indeces in the feature map .
The essence behind our RSA unit is to derive a mapping RSA ( ) ? f ( ) to constantly predict smaller - scale features based on the current map instead of feeding the network with inputs of different scales for multiple times .
In an informal mathematical expression , we have :
to indicate the functionality of RSA : an approximation to f ( ) from the input at the largest scale 0 to its desired level m .
The computation cost of generating feature map F m using RSA is much lower than that of resizing the image and feeding into the network ( i.e. , f ( I m ) through conv1 to res2b ; see quantitative results in Section 4.4 ) .
During inference , we first obtain the possible scales of the input from the scale - forecast network .
The image is then resized accordingly so that the smallest scale ( corresponding to the largest feature map ) is resized to the range of [ 64 , 128 ] .
The feature maps at other scales are thereby predicted by the output of RSA unit via Eqn ( 6 ) .
depicts a rolled - out version of RSA to predict feature maps of smaller scales compared with the ground truth .
We can observe from both the error rate and predicted feature maps in each level that RSA is capable of approximating the feature maps at smaller scales .
Landmark Retracing Network
In the task of face detection , as illustrated in , the landmark retracing network ( LRN ) is designed to adjust the confidence of identifying a face and to dispose of false positives by learning individual confidence of each regressed landmark .
Instead of directly using the ground truth location of landmarks , we formulate such a feature learning of landmarks based on the regression output of landmarks in the final RPN layer .
Specifically , given the feature map F at a specific scale from RSA ( m is dropped for brevity ) , we first feed it into the res3a layer .
There are two branches at the output : one is the landmark feature set P to predict the individual score of each landmark in a spatial context .
The number of channels in the set equals to the number of landmarks .
Another branch is continuing the standard RPN pipeline ( res3 b - 3 c ) which generates a set of anchors in the final RPN layer .
Let pi = [ p i 0 , p i 1 , , p ik , ] denote the classification probability in the final RPN layer , where k is the class index and i is the spatial location index on the map ; t ij denotes the regression target ( offset defined in ) of the j - th landmark in the i - th anchor , where j = { 1 , , 5 } is the landmark index .
Note that in face detection task , we only have one anchor so that pi contains one element .
In the traditional detection - to - landmark formulation , the following loss , which consists of two heads ( i.e. , classification and regression ) , is optimized :
where ? ( ) is the indicator function ; k * denotes the correct label of anchor i and we have only two classes here ( 0 for background , 1 for positive ) ; t * i is the ground truth regression target and S ( ) is the smoothing l 1 loss defined in .
However , as illustrated in , using the confidence of anchor p ik * alone results in false positives in some cases , which inspires us to take advantage of the landmark features based on the regression output .
The revised classification output , p trace ik * ( t ij ) , now considers both the feature in the final RPN layer as well as those in the landmark feature set :
where p land ij is the classification output of point j from the landmark feature set P and it is determined by the regression output :
where r ( ) stands for a mapping from the regression target to the spatial location on map P .
To this end , we have the revised loss for our landmark retracing network :
( 11 ) Apart from the detection - to - landmark design as previous work did , our retracing network also fully leverages the feature set of landmarks to help rectify the confidence of identifying a face .
This is achieved by utilizing the regression output t ij to find the individual score of each landmark on the preceding feature map P. Such a scheme is in a landmark - to - detection spirit .
Note that the landmark retracing network is trained endto - end with the RSA unit stated previously .
The anchor associated with each location i is a square box of fixed size 64 ?
2 . The landmark retracing operation is performed only when the anchor is a positive sample .
The base landmark location with respect to the anchor is determined by the average location of all faces in the training set .
During test , LRN is fed with feature maps at various scales and it treats each scale individually .
The final detection result is generated after performing NMS among results from multi-scales .
Discussion
Comparison to RPN .
The region proposal network takes a set of predefined anchors of different sizes as input and conducts a similar detection pipeline .
Anchors in RPN vary in size to meet the multi-scale training constraint .
During one iteration of update , it has to feed the whole image of different sizes ( scales ) from the start to the very end of the network .
In our framework , we resize the image once to make sure at least one face falls into the size of [ 64 , 128 ] , thus enforcing the network to be trained within a certain range of scales .
In this way , we are able to use only one anchor of fixed size .
The multi-scale spirit is embedded in an RSA unit , which directly predicts the feature maps at smaller scales .
Such a scheme saves parameters significantly and could be considered as a ' semi ' multi-scale training and ' fully ' multi-scale test .
Prediction - supervised or GT - supervised in landmark feature sets .
Another comment on our framework is the supervision knowledge used in training the landmark features P .
The features are learned using the prediction output of regression targets t ij instead of the ground truth targets t * ij .
In our preliminary experiments , we find that if p land i ? t * i , the activation in the landmark features would be heavily suppressed due to the misleading regression output by t ij ; however , if we relax the learning restriction and accept activations within a certain range of misleading locations , i.e. , p land i ? ti , the performance can be boosted further .
Using the prediction of regression as supervision in the landmark feature learning makes sense since : ( a ) we care about the activation ( classification probability ) rather than the accurate location of each landmark ; ( b ) ti and p land i share similar learning workflow and thus the location oft i could better match the activation p land i in P.
Experiments
In this section we first conduct the ablation study to verify the effectiveness of each component in our method and compare exhaustively with the baseline RPN ; then we compare our algorithm with state - of - the - art methods in face detection and object detection on four popular benchmarks .
Setup and Implementation Details
Annotated Faces in the Wild ( AFW ) contains 205 images for evaluating face detectors ' performance .
However , some faces are missing in the annotations and could trigger the issue of false positives , we relabel those missing faces and report the performance difference in both cases .
Face Detection
Data Set and Benchmark ( FDDB ) has 5,171 annotated faces in 2,845 images .
It is larger and more challenging than AFW .
Multi - Attribute Labelled Faces ( MALF ) includes 5,250 images with 11,931 annotated faces collected from the Internet .
The annotation set is cleaner than that of AFW and it is the largest benchmark for face detection .
Our training set has 184K images , including 171K images collected from the Internet and 12.9 K images from the training split of Wider Face Dataset .
All faces are labelled with bounding boxes and five landmarks .
The structure of our model is a shallow version of the ResNet where the first seven ResNet blocks are used , i.e. , from conv1 to res3c .
We use this model in scale - forecast network and LRN .
All numbers of channels are set to half of the original ResNet model , for the consideration of time efficiency .
We first train the scale - forecast network and then use the output of predicted scales to launch the RSA unit and LRN .
Note that the whole system ( RSA + LRN ) is trained end - to - end and the model is trained from scratch without resorting to a pretrained model since the number of channels is halved .
The ratio of the positive and the negative is 1 : 1 in all experiments .
The batch size is 4 ; base learning rate is set to 0.001 with a decrease of 6 % every 10,000 iterations .
The maximum training iteration is 1,000,000 .
We use stochastic gradient descent as the optimizer .
The scale - forecast network is of vital importance to the computational cost and accuracy in the networks afterwards .
reports the overall recall with different numbers of predicted scales on three benchmarks .
Since the number of faces and the number of potential scales in the image vary across datasets , we use the number of predicted scales per face ( x , total predicted scales over total number of faces ) and a global recall ( y , correct predicted scales overall ground truth scales ) as the evaluation metric .
We can observe from the results that our trained scale network recalls almost 99 % at x = 1 , indicating that on average we only need to generate less than two predictions per image and that we can retrieve all face scales .
Based on this prior final feature .
Investigation on the source layer to branch out the RSA unit .
For each case , we report the error rate v.s. the level of down - sampling ratio in the unit .
We can conclude that the deeper the RSA is branched out , the worse the feature approximation at smaller scales will be .
knowledge , during inference , we set the threshold for predicting potential scales of the input so that it has approximately two predictions .
investigates the effect of appending the RSA unit to different layers .
For each case , the error rate between the ground truth and corresponding prediction is computed .
We define the error rate ( ER ) on level m as :
Performance of Scale - forecast Network
Ablative Evaluation on RSA Unit
where '. /' implies an element - wise division between maps ; N is the total number of samples .
We use a separate validation set to conduct this experiment .
The image is first resized to higher dimension being 2048 and the RSA unit predicts six scales defined in Section 3.1 ( 1024 , 512 , 256 , 128 and 64 ) .
Ground truth maps are generated accordingly as we iteratively resize the image ( see ) .
There are two remarks regarding the result : First , feature depth matters .
Theoretically RSA can handle all scales of features in a deep CNN model and therefore can be branched out at any depth of the network .
However , results from the figure indicate that as we plug RSA at deeper layers , its performance decades .
Since features at deeper layers are more sparse and abstract , they barely contain information for RSA to approximate the features at smaller scales .
For example , in case final feature which means RSA is plugged at the final convolution layer after res3c , the error rate is almost 100 % , indicating RSA 's incapability of handling the insufficient information in this layer .
The error rate decreases in shallower cases .
However , the computation cost of RSA at shallow layers is much higher than that at deeper layers , since the stride is .
The proposed algorithm is more computationally efficient and accurate by design than baseline RPN .
Theoretical operations of each component are provided , denoted as ' Opts. ( VGA input ) ' below .
The minimum operation in each component means only the scaleforecast network is used where no face appears in the image ; and the maximum operation indicates the amount when faces appear at all scales .
The actual runtime comparison between ours and baseline RPN is reported in smaller and the input map of RSA is thus larger .
The path during one - time forward from image to the input map right before RSA is shorter ; and the rolling out time increases accordingly .
Therefore , the trade - off is that we want to plug RSA at shallow layers to ensure a low error rate and at the same time , to save the computational cost .
In practice we choose case res2b to be the location where RSA is branched out .
Most of the computation happens before layer res2 b and it has an acceptable error rate of 3.44 % .
We use this setting throughout the following experiments .
Second , butterfly effect exists .
For a particular case , as the times of the recurrent operation increase , the error rate goes up due to the cumulative effect of rolling out the predictions .
For example , in case res2b , the error rate is 3.44 % at level m = 1 and drops to 5.9 % after rolling out five times .
Such an increase is within the tolerance of the system and still suffices the task of face detection .
Our Algorithm vs. Baseline RPN
We compare our model ( denoted as RSA + LRN ) , a combination of the RSA unit and a landmark retracing network , with the region proposal network ( RPN ) .
In the first setting , we use the original RPN with multiple anchors ( denoted as RPN m ) to detect faces of various scales .
In the second setting , we modify the number of anchors to one ( denoted as RPN s ) ; the anchor can only detect faces in the range from 64 to 128 pixels .
To capture all faces , it needs to take multiple shots in an image pyramid spirit .
The network structurse of both baseline RPN and our LRN descend from ResNet - 18 .
Anchor sizes in the first setting RPN mare 32 ? 2 , 64 ? 2 , , 1024 ?
2 and they are responsible for detecting faces in the range of , [ 64 , 128 ) , , [ 1024 , 2048 ] , respectively .
In the second setting RPN s , we first resize the image length to 64 , 256 , , 2048 , then test each scale individually and merge all results through NMS .
shows the theoretical computation cost and test performance of our algorithm compared with baseline RPN .
We can observe that RPN s needs six shots for the same image during inference and thus the computation cost is much larger than ours or RPN m ; Moreover , RPN m performs worse than the rest two for two reasons :
First , the receptive field is less than 500 and therefore it can not seethe context of faces larger than 500 pixels ; second , it is hard for the network ( it s model capacity much less than the original ResNet ) to learn the features of faces in a wide scale range from 32 to 2048 .
depicts the runtime comparison during test .
The third column LRN means without using the RSA unit .
Our method runs fast enough compared with its counterparts for two reasons .
First , there are often one or two valid scales in the image , and the scale - forecast network can automatically select some particular scales , and ignore all the other invalid ones in the multi -scale test stage ; second , the input of LRN descends from the output of RSA to predict feature maps at smaller scales ; it is not necessary to compute feature maps of multiple scales in a multi- shot manner as RPN m does .
shows the comparison against other approaches on three benchmarks .
On AFW , our algorithm achieves an AP of 99.17 % using the original annotation and an AP of 99 . 96 % using the revised annotation 7 ( c ) .
On FDDB , RSA + LRN recalls 93.0 % faces with 50 false positives 7 ( a ) .
On MALF , our method recalls 82.4 % faces with zero false positive 7 ( d ) .
It should be noticed that the shape and scale definition of bounding box on each benchmark varies .
For instance , the annotation on FDDB is ellipse while others are rectangle .
To address this , we learn a transformer to fit each annotation from the landmarks .
This strategy significantly enhances performance in the continuous setting on FDDB ..
Our proposed model can detect faces at various scales , including the green annotations provided in AFW as well as faces marked in red that are of small sizes and not labeled in the dataset ..
Comparison to state - of - the - art approaches on face detection benchmarks .
The proposed algorithm ( Scale - forecast network with RSA + LRN , tagged by LRN + RSA ) outperforms other methods by a large margin .
' revised gt. ' and ' original gt. ' in AFW stand for fully annotated faces by us and partially labeled annotations provided by the dataset , respectively .
Face Detection
RSA on Generic Object Proposal
We now verify that the scale approximation learning by RSA unit also generalizes comparably well on the generic region proposal task .
Region proposal detection is a basic stage for generic object detection task and is more difficult than face detection .
ILSVRC DET is a challenging dataset for generic object detection .
It contains more than 300K images for training and 20K images for validation .
We use a subset ( around 170 k images ) of the original training set for training , where each category has at most 1000 samples ; for test we use the val2 split with 9917 images .
We choose the single anchor RPN with ResNet - 101 as the baseline .
RSA unit is set after res3b3 .
The anchors are of size 128 ? 2 squared , 128256 and 256128 .
During training , we randomly select an object and resize the image so that the object is rescaled to .
Scale - forecast network is also employed to predict the higher dimension of objects in the image .
Recalls with different number of proposals are shown in .
The original RPN setting has 18 anchors with 3 as - pect ratios and 6 scales .
Without loss of recall , RPN + RSA reduces around 61.05 % computation cost compared with the single - scale RPN , when the number of boxes is over 100 .
RPN + RSA is also more efficient and recalls more objects than original RPN .
Our model and the single - anchor RPN both perform better than the original RPN .
This observation is in accordance with the conclusion in face detection .
Overall , our scheme of using RSA plus LRN competes comparably with the standard RPN method in terms of computation efficiency and accuracy .
Conclusion
In this paper , we prove that deep CNN features of an image can be approximated from a large scale to smaller scales by the proposed RSA unit , which significantly accelerates face detection while achieving comparable results in object detection .
In order to make the detector faster and more accurate , we devise a scale - forecast network to predict the potential object scales .
We further design a landmark retracing network to fuse global and local scale information to enhance the predictor .
Experimental results show that our algorithm significantly outperforms state - of - the - art methods .
Future work includes exploring RSA on generic object detection task .
Representation approximation between video frames is also an interesting research avenue .
