title
Robust Face Detection via Learning Small Faces on Hard Images
abstract
Recent anchor - based deep face detectors have achieved promising performance , but they are still struggling to detect hard faces , such as small , blurred and partially occluded faces .
A reason is that they treat all images and faces equally , without putting more effort on hard ones ; however , many training images only contain easy faces , which are less helpful to achieve better performance on hard images .
In this paper , we propose that the robustness of a face detector against hard faces can be improved by learning small faces on hard images .
Our intuitions are ( 1 ) hard images are the images which contain at least one hard face , thus they facilitate training robust face detectors ; ( 2 ) most hard faces are small faces and other types of hard faces can be easily converted to small faces by shrinking .
We build an anchor-based deep face detector , which only output a single feature map with small anchors , to specifically learn small faces and train it by a novel hard image mining strategy .
Extensive experiments have been conducted on WIDER FACE , FDDB , Pascal Faces , and AFW datasets to show the effectiveness of our method .
Our method achieves APs of 95.7 , 94.9 and 89.7 on easy , medium and hard WIDER FACE val dataset respectively , which surpass the previous state - of - the - arts , especially on the hard subset .
Code and model are available at https
Introduction
Face detection is a fundamental and important computer vision problem , which is critical for many face - related tasks , such as face alignment , tracking and recognition .
Stem from the recent successful development of deep neural networks , massive CNN - based face detection approaches have been proposed and achieved the state - of - the - art performance .
However , face detection remains a challenging task due to occlusion , illumination , makeup , as well as pose and scale variance , as shown in the benchmark dataset WIDER FACE .
Current state - of - the - art CNN - based face detectors at - tempt to address these challenges by employing more powerful backbone models , exploiting feature pyramid - style architectures to combine features from multiple detection feature maps , designing denser anchors and utilizing larger contextual information .
These methods and techniques have been shown to be successful to build a robust face detector , and improve the performance towards human - level for most images .
In spite of their success for most images , an evident performance gap still exists especially for those hard images which contain small , blurred and partially occluded faces .
We realize that these hard images have become the main barriers for face detectors to achieve human - level detection performance .
In , we show that , even on the train set of WIDER FACE , the official pre-trained SSH 1 still fails on some of the images with extremely hard faces .
We show two such hard training images in the upper right corner in .
On the other hand , most training images with easy faces can be almost perfectly detected ( see the illustration in the right lower corner of ) .
As shown in left part of , over two thirds of the training images already obtained perfect detection accuracy , which indicates that those easy images are less useful towards training a robust face detector .
To address this issue , in this paper , we propose a robust face detector by putting more training focus on those hard images .
This issue is most related to anchor - level hard example mining discussed in OHEM .
However , due to the sparsity of ground - truth faces and positive anchors , traditional anchor - level hard example mining mainly focuses on mining hard negative anchors , and mining hard anchors on well - detected images exhibits less effectiveness since there is no useful information that can be further exploited in these easy images .
To address this issue , we propose to mine hard examples at image level in parallel with anchor level .
More specifically , we propose to dynamically assign difficulty scores to training images during the learning process , which can determine whether an image is already well - detected or still useful for further training .
This allows us to fully utilize the images which were not perfectly detected to better facilitate the following learning process .
We show this strategy can make our detector more robust towards hard faces , without involving more complex network architecture and computation overhead .
Apart from mining the hard images , we also propose to improve the detection quality by exclusively exploiting small faces .
Small faces are typically hard and have attracted extensive research attention .
Existing methods aim at building a scale - invariant face detector to learn and infer on both small and big faces , with multiple levels of detection features and anchors of different sizes .
Compared with these methods , our detector is more efficient since it is specially designed to aggressively leveraging the small faces during training .
More specifically , large faces are automatically ignored during training due to our anchor design , so that the model can fully focus on the small hard faces .
Additionally , experiments demonstrate that this design effectively achieves improvements on detecting all faces in spite of its simple and shallow architecture .
To conclude , in this paper , we propose a novel face detector with the following contributions :
We propose a hard image mining strategy , to improve the robustness of our detector to those extremely hard faces .
This is done without any extra modules , parameters or computation overhead added on the existing detector .
We design a single shot detector with only one detection feature map , which focuses on small faces with a specific range of sizes .
This allows our model to be simple and focus on difficult small faces without struggling with scale variance .
Our face detector establishes state - of - the - art performance on all popular face detection datasets , including WIDER FACE , FDDB , Pascal Faces , and AFW .
We achieve 95.7 , 94.9 and 89.7 on easy , medium and hard WIDER FACE val dataset .
Our method also achieves APs of 99.00 and 99.60 on Pascal Faces and AFW respectively , as well as a TPR of 98.7 on FDDB .
The remainder of this paper is organized as follows .
In Section 2 , we discuss some studies have been done which are related to our paper .
In Section 3 , we dive into details of our proposed method , and we discuss experiment results and ablation experiments in Section 4 .
Finally , conclusions are drawn in Section 5 .
Related work
Face detection has received extensive research attention .
With the emergence of modern CNN and object detector , there are many face detectors proposed to achieve promising performances , by adapting general object detection framework into face detection domain .
We briefly review hard example mining , face detection architecture , and anchor design & matching .
Hard example mining
Hard example mining is an important strategy to improve model quality , and has been studied extensively in image classification and general object detection .
The main idea is to find some hard positive and hard negative examples at each step , and put more effort into training on those hard examples .
Recently , with modern detection frameworks proposed to boost the performance , OHEM and Focal loss have been proposed to select hard examples .
OHEM computed the gradients of the networks by selecting the proposals with highest losses in every minibatch ; while Focal loss aimed at naturally putting more focus on hard and misclassified examples by adding a factor to the standard cross entropy criterion .
However , these algorithms mainly focused on anchor - level or proposal - level mining .
It can not handle the imbalance of easy and hard images in the dataset .
In our paper , we propose to exploit hard example mining on image level , i.e. hard image mining , to improve the quality of face detector on extremely hard faces .
More specifically , we assign difficulty scores to training images while training with an SGD mechanism , and re-sample the training images to build a new training subset at the next epoch .
Face Detection Architecture
Recent state - of - the - art face detectors are generally built based on Faster - RCNN , R - FCN or SSD .
SSH exploited the RPN ( Region Proposal Network ) from Faster - RCNN to detect faces , by building three detection feature maps and designing six anchors with different sizes attached to the detection feature maps .
S 3 FD and PyramidBox , on the other hand , adopted SSD as their detection architecture with six different detection feature :
The framework of our face detector .
We take VGG16 as our backbone CNN , and we fuse two layers ( conv4 3 and conv 5 3 ) after dimension reduction and bilinear upsampling , to generate the final detection feature map .
Based on that , we add a detection head for classification and bounding - box regression .
maps .
Different from S 3 FD , Pyramid Box exploited a feature pyramid - style structure to combine features from different detection feature maps .
Our proposed method , on the other hand , only builds single level detection feature map , based on VGG16 , for classification and bounding - box regression , which is both simple and effective .
Anchor design and matching
Usually , anchors are designed to have different sizes to detect objects with different scales , in order to build a scaleinvariant detector .
SSD as well as its follow - up detectors S 3 FD and PyramidBox , had six sets of anchors with different sizes , ranging from ( 16 16 ) to ( 512 512 ) , and their network architectures had six levels of detection feature maps , with resolutions ranging from 1 4 to 1 128 , respectively .
Similarly , SSH had the same anchor setting , and those anchors were attached to three levels of detection feature maps with resolutions ranging from 1 8 to .
The difference between SSH and S 3 DF is that in SSH , anchors with two neighboring sizes shared the same detection feature map , while in S 3 DF , anchors with different sizes are attached to different detection feature maps .
SNIP discussed an alternative approach to handle scales .
It showed that CNNs are not robust to changes in scale , so training and testing on the same scales of an image pyramid can be a more optimal strategy .
In our paper , we exploit this idea by limiting the anchor sizes to be ( 1616 ) , ( 32 32 ) and ( 64 64 ) .
Then those faces with either too small or too big sizes will not be matched to any of the anchors , thus will be ignored during the training and testing .
By removing those large anchors with sizes larger than ( 64 64 ) , our network focuses more on small faces which are potentially more difficult .
To deal with large faces , we use multiscale training and testing to resize them to match our anchors .
Experiments show this design performs well on both small and big faces , although it has fewer detection feature maps and anchor sizes .
Proposed method
In this section , we introduce our proposed method for effective face detection .
We first discuss the architecture of our detector in Section 3.1 , then we elaborate our hard image mining strategy in Section 3.2 , as well as some other useful training techniques in Section 3.3 .
Single - level small face detection framework
The framework of our face detector is illustrated in Figure 2 .
We use VGG16 network as our backbone CNN , and combine conv4 3 and conv5 3 features , to build the detection feature map with both low - level and high - level semantic information .
Similar to SSH , we apply 11 convolution layers after conv4 3 and conv5 3 to reduce dimension , and then apply a 33 convolution layer on the concatenation of these two dimension reduced features .
The output feature of the 33 convolution layer is the final detection feature map , which will be fed into the detection head for classification and bounding - box regression .
The detection feature map has a resolution of 1 8 of the original image ( of size H W ) .
We attach three anchors at each point in the grid as default face detection boxes .
Then we do classification and bounding - box regression on those 3 H 8 W 8 anchors .
Unlike many other face detectors which build multiple feature maps to detect face with a variant range of scales , inspired by SNIP , faces are trained and inferred with roughly the same scales .
We only have one detection feature map , with three sets of anchors attached to it .
The anchors have sizes of ( 16 16 ) , :
The framework of our dilated detection head for classification and regression .
Based on the detection feature from the backbone CNN , we first perform a dimension reduction to reduce the number of channels from 512 to 128 .
Then we put three convolution layers with the shared weight , and different dilation rates , to generate final detection and classification features .
and ( 64 64 ) , and the aspect ratio is set to be 1 .
By making this configuration , our network only trains and infers on small and medium size of faces ; and we propose to handle large faces by shrinking the images in the test phase .
We argue that there is no speed or accuracy degradation for large faces , since inferring on a tiny image ( with short side containing 100 or 300 pixels ) is very fast , and the shrinked large face will still have enough information to be recognized .
To handle the difference of anchor sizes attached to the same detection feature map , we propose a detection head which uses different dilation rates for anchors with different sizes , as shown in .
The intuition is that in order to detect faces with different sizes , different effective receptive fields are required .
This naturally requires the backbone feature map to be invariant to scales .
To this end , we adopt different dilation rates for anchors with different sizes .
For anchors with size ( 16 16 ) , ( 32 32 ) and ( 64 64 ) , we use a convolution with kernel size of 3 and dilation rate of 1 , 2 and 4 to gather context features at different scales .
These three convolution layers share weights to reduce the model size .
With this design , the input of the 3 3 convolution , will be aligned to the same location of faces , regardless of the size of faces and anchors .
Ablation experiments show the effectiveness of this multi-dilation design .
Hard image mining
Different from OHEM discussed in Section 3.3 , which selects proposals or anchors with the highest losses , we propose a novel hard image mining strategy at image level .
The intuition is that most images in the dataset are very easy , and we can achieve a very high AP even on the hard subset of the WIDER FACE val dataset with our baseline model .
We believe not all training images should be treated equally , and well - recognized images will not help towards training a more robust face detector .
To put more attention on training hard images instead of easy ones , we use a subset D of all training images D , to contain hard ones for training .
At the beginning of each epoch , we build D based on the difficulty scores obtained in the previous epoch .
We initially use all training images to train our model ( i.e. D = D ) .
This is due to the fact that our initial Im - age Net pre-trained model will only give random guess towards face detection .
In this case , there is no easy image .
In other words , every image is considered as hard image and fed to the network for training at the first epoch .
During the training procedure , we dynamically assign different difficulty scores to training images , which is defined by the metric where A ( I ) + is the set of positive anchors for image I , with IoU over 0.5 against ground - truth boxes , l is the classification logit and l ( I ; ? ) a , 1 , l ( I ; ? ) a , 0 are the logits of anchor a for image Ito be foreground face and background .
All images are initially marked as hard , and any image with WPAS greater than a threshold th will be marked as easy image .
At the beginning of each epoch , we first randomly shuffle the training dataset to generate the complete training list D = [ I i 1 , I i2 , , I in ] for the following epoch of training .
Then given an image marked as easy , we remove it from D with a probability of p.
The remaining training list D = [ I ij i , I ij 2 , , I ij k ] , which focuses more on hard images , will be used for training at this epoch .
Note that for multi - GPU training , each GPU will maintain its training list D independently .
In our experiments , we set the probability p to be 0.7 , and the threshold th to be 0.85 .
Training strategy
Multi - scale training and anchor matching
Since we only have anchors covering a limited range of face scales , we train our model by varying the sizes of training images .
During the training phase , we resize the training images so that the short side of the image contains s pixels , where sis randomly selected from { 400 , 800 , 1200 } .
We also set an upper bound of 2000 pixels to the long side of the image considering the GPU memory limitation .
For each anchor , we assign a label { + 1 , 0 , ? 1 } based on how well it matches with any ground - truth face bounding box .
If an anchor has an IoU ( Intersection over Union ) over 0.5 against a ground - truth face bounding box , we assign + 1 to that anchor .
On the other hand , if the IoU against any ground - truth face bounding box is lower than 0.3 , we assign 0 to that anchor .
All other anchors will be given ? 1 as the label , and thus will be ignored in the classification loss .
By doing so , we only train on faces with designated scales .
Those faces with no anchor matching will be simply ignored , since we do not assign the anchor with largest IoU to it ( thus assign the corresponding anchor label + 1 ) as Faster - RCNN does .
This anchor matching strategy will ignore the large faces , and our model can put more capacity on learning different face patterns on hard small faces instead of memorizing the change in scales .
For the regression loss , all anchors with IoU greater than 0.3 against ground - truth faces will betaken into account and contribute to the smooth 1 loss .
We use a smaller threshold ( i.e. 0.3 ) because ( 1 ) this will allow imperfectly matched anchors to be able to localize the face , which maybe useful during the testing and ( 2 ) the regression task has less supervision since unlike classification , there are no negative anchors for computing loss and the positive anchors are usually sparse .
Anchor - level hard example mining
OHEM has been proven to be useful for object detection and face detection in .
During our training , in parallel with our newly proposed hard image mining , we also exploit the traditional hard anchor mining method to focus more on the hard and misclassificed anchors .
Given a training image with size H W , there are 3 H 8 W 8 anchors at the detection head , and we only select 256 of them to be involved in computing the classification loss .
For all positive anchors with IoU greater than 0.5 against ground - truth boxes , we select the top 64 of them with lowest confidences to be recognized as face .
After selecting positive anchors , ( 256 ?
#pos anchor ) negative anchors with highest face confidence are selected to compute the classification loss as the hard negative anchors .
Note that we only perform OHEM for classification loss , and we keep all anchors with IoU greater than 0.3 for computing regression loss , without selecting a subset based on either classification loss or bounding - box regression loss .
Data augmentation
Data augmentation is extremely useful to make the model robust to light , scale changes and small shifts .
In our proposed method , we exploit cropping and photometric distortion as data augmentation .
Given a training image after resizing , we crop a patch of it with a probability of 0.5 .
The patch has a height of H and a width of W which are independently drawn from U ( 0.6H , H ) and U ( 0.6 W , W ) , where U is the uniform distribution and H , Ware the height and width of the resized training image .
All ground - truth boxes whose centers are located inside the patch are kept .
After the random cropping , we apply photometric distortion following SSD by randomly modifying the brightness , contrast , saturation and hue of the cropped image randomly .
Experiments
To verify the effectiveness of our model and proposed method , we conduct extensive experiments on popular face detection datasets , including WIDER FACE , FDDB , Pascal Faces and AFW .
It is worth noting that the training is only performed on the train set of WIDER FACE , and we use the same model for evaluation on all these datasets without further fine - tuning .
Experimental settings
We train our model on the train set of WIDER FACE , which has 12880 images with 159 k faces annotated .
We flip all images horizontally , to double the size of our training dataset to 25760 .
For each training image , we first randomly resize it , and then we use the cropping and photometric distortion data augmentation methods discussed in Section 3.3 to pre-process the resized image .
We use an ImageNet pretrained VGG16 model to initialize our network backbone , and our newly introduced layers are randomly initialized with Gaussian initialization .
We train the model with the itersize to be 2 , for 46 k iterations , with a learning rate of 0.004 , and then for another 14 k iterations with a smaller learning rate of 0.0004 .
During training , we use 4 GPUs to simultaneously to compute the gradient and update the weight by synchronized SGD with Momentum .
The first two blocks of VGG16 are frozen during the training , and the rest layers of VGG16 are set to have a double learning rate .
Since our model is designed and trained on only small faces , we use a multiscale image pyramid for testing to deal with faces larger than our anchors .
Specifically , we resize the testing image so that the short side contains 100 , 300 , 600 , 1000 and 1400 pixels for evaluation on WIDER FACE dataset .
We also follow the testing strategies used in Pyra - midBox 2 such as horizontal flip and bounding - box voting .
Experiment results
WIDER FACE dataset includes 3226 images and 39708 faces labelled in the val dataset , with three subsetseasy , medium and hard .
In , we show the precision - recall ( PR ) curve and average precision ( AP ) for our model compared with many other state - of - the - arts on these three subsets .
As we can see , our method achieves the best performance on the hard subset , and outperforms the current state - of - the - art by a large margin .
Since the hard set is a super set of small and medium , which contains all faces taller than 10 pixels , the performance on hard set can represent the performance on the full testing dataset more accurately .
Our performance on the medium subset is comparable to the most recent state - of - the - art and the performance on the easy subset is a bit worse since our method focuses on learning hard faces , and the architecture of our model is simpler compared with other state - of - thearts .
There is also a WIDER FACE test dataset with no annotations provided publicly .
It contains 16097 images , and is evaluated by WIDER FACE author team .
We report the performance of our method at for the hard subset .
FDDB dataset includes 5171 faces on a set of 2845 images , and we use our model trained on WIDER FACE train set to infer on the FDDB dataset .
We use the raw boundingbox result without fitting it into ellipse to compute ROC .
We show the discontinuous ROC curve at compared with , and our method achieves the state - of - the - art performance of TPR = 98.7 % given 1000 false positives .
Pascal Faces dataset includes 1335 labeled faces on a set of 851 images extracted for the Pascal VOC dataset .
We show the PR curve at compared with , and our method achieves a new the state - of - the - art performance of AP = 99.0 .
AFW dataset includes 473 faces labelled in a set of 205 images .
As shown in compared with , our method achieves state - of - the - art and almost perfect performance , with an AP of 99.60 .
Ablation study and diagnosis Ablation experiments
In order to verify the performance of our single level face detector , as well as the effectiveness of our proposed hard image mining , the dilated - head classification and regression structure , we conduct various ablation experiments on the WIDER FACE val dataset .
All results are summarized in .
From , we can see that our single level baseline model can achieve performance comparable to the current : Ablation experiments .
Baseline - Three is a face detector similar to SSH with three detection feature maps .
Baseline - Single is our proposed detector with single detection feature map shown in .
HIM and DH represents hard image mining ( Subsection 3.2 ) and dilated head architecture ) .
state - of - the - art face detector , especially on the hard subset .
Our model with single detection feature map performs better than the one with three detection feature maps , despite its shallower structure , fewer parameters and anchors .
This confirms the effectiveness of our simple face detector with single detection feature map focusing on small faces .
We also separately verify our newly proposed hard image mining ( HIM ) and dilated head architecture ( DH ) described in Subsection 3.2 and respectively .
HIM can improve the performance on hard subset significantly without involving more complex network architecture nor computation overhead .
DH itself can also boost the performance , which shows the effectiveness of designing larger convolution for larger anchors .
Combining HIM and DH together can improve further towards the state - of - the - art performance .
Diagnosis of hard image mining
We investigate the effects of our hard image mining mechanism .
We show the ratio of | D | and | D ? D | ( i.e. the ratio of the number of selected training images to the number of ignored training images ) in for each epoch .
We can see that at the first epoch , all training images are used to train the model .
Meanwhile , as the training process continues , more and more training images will be ignored .
At the last epoch , over a half images will be ignored and thus will not be included in D .
Diagnosis of data augmentation
We investigate the effectiveness of the photometric distortion as well as the cropping mechanisms as discussed in Subsection 3.3 .
The ablation results evaluated on WIDER FACE val dataset are shown in .
Both photometric distortion and cropping can contribute to a more robust face detector .
Diagnosis of multi-scale testing
Our face detector with one detection feature map is design for small face detection , and our anchors are only capable of capturing faces with sizes ranging from ( 64 64 ) .
As a result , it is critical to adopt multi-scale testing to deal with large faces .
Different from SSH , S 3 FD and PyramidBox , our testing pyramid includes some extreme small scales ( i.e. short side contains only 100 or 300 pixels ) .
In , we show the effectiveness of these extreme small scales to deal with easy and large images .
Our full evaluation resizes the image so that the short side contains 100 , 300 , 600 , 1000 and 1400 pixels respectively , to build an image pyramid .
We diagnose the impact of the extra small scales ( i.e. 100 and 300 ) by removing them from the image pyramid . :
Diagnosis of multi-scale testing. , the extra small scales are crucial to detect easy faces .
Without resizing the short side to contain 100 and 300 pixels , the performance on easy subset is only 78.2 , which is even lower than the performance on medium and hard which contain much harder faces .
We will show in the next subsection that these extra small scales ( 100 and 300 ) lead to negligible computation overhead , due to the lower resolution .
As shown in
Diagnosis of accuracy / speed trade - off
We evaluate the speed of our method as well as some other popular face detectors in .
For fair comparison , we run all methods on the same machine , with one Titan X ( Maxwell ) GPU , and Intel
Core i7-4770K
3.50 GHz .
All methods except for Pyramid Box are based on Caffe1 implementation , which is compiled with CUDA 9.0 and CUDNN 7 .
For PyramidBox , we follow the official fluid code and the default configurations 3 .
We use the officially built Pad - dlePaddle with CUDA 9.0 and CUDNN 7 .
For SSH , S 3 FD and Pyramid , we use the official inference code and configurations .
For SSH , we use multi-scale testing with the short side containing 500 , 800 , 1200 and 1600 pixels , and for S 3 FD , we execute the official evaluation code with both multi-scale testing and horizontal flip .
Pyramid
Box takes a similar testing configuration as S 3 FD .
As shown in , our detector can outperform SSH , S 3 FD and PyramidBox significantly with a smaller inference time .
Based on that , using horizontal flip can further improve the performance slightly .
In terms of GPU memory usage , our method uses only a half of what PyramidBox occupies , while achieving better performance .
Ours * in indicates our method without extra small scales in inference , i.e. , evaluated with scales [ 600 , 1000 , 1400 ] .
It is only 6.5 % faster than evaluation with [ 100 , 300 , 600 , 1000 , 1400 ] ( 1.59 compared with 1.70 ) .
This proves that although our face detector is only trained on small faces , it can perform well on large faces , by simply shrinking the testing image with negligible computation overhead .
Conclusion
To conclude , we propose a novel face detector to focus on learning small faces on hard images , which achieves the state - of - the - art performance on all popular face detection datasets .
We propose a hard image mining strategy by dynamically assigning difficulty scores to training images , and re-sampling subsets with hard images for training before each epoch .
We also design a single shot face detector with only one detection feature map , to train and test on small faces .
With these designs , our model can put more attention on learning small hard faces instead of memorizing change of scales .
Extensive experiments and ablations have been done to show the effectiveness of our method , and our face detector achieves the state - of - the - art performance on all popular face detection datasets , including WIDER FACE , FDDB , Pascal Faces and AFW .
Our face detector also enjoys faster multi-scale inference speed and less GPU memory usage .
Our proposed method are flexible and can be applied to other backbones and tasks , which we remain as future work .
