title
WIDER FACE : A Face Detection Benchmark
abstract
Face detection is one of the most studied topics in the computer vision community .
Much of the progresses have been made by the availability of face detection benchmark datasets .
We show that there is a gap between current face detection performance and the real world requirements .
To facilitate future face detection research , we introduce the WIDER FACE dataset , which is 10 times larger than existing datasets .
The dataset contains rich annotations , including occlusions , poses , event categories , and face bounding boxes .
Faces in the proposed dataset are extremely challenging due to large variations in scale , pose and occlusion , as shown in Fig .
1 . Furthermore , we show that WIDER FACE dataset is an effective training source for face detection .
We benchmark several representative detection systems , providing an overview of state - of - the - art performance and propose a solution to deal with large scale variation .
Finally , we discuss common failure cases that worth to be further investigated .
Dataset can be downloaded at : mmlab.ie.cuhk.edu.hk/projects/WIDERFace
Introduction
Face detection is a critical step to all facial analysis algorithms , including face alignment , face recognition , face verification , and face parsing .
Given an arbitrary image , the goal of face detection is to determine whether or not there are any faces in the image and , if present , return the image location and extent of each face .
While this appears as an effortless task for human , it is a very difficult task for computers .
The challenges associated with face detection can be attributed to variations in pose , scale , facial expression , occlusion , and lighting condition , as shown in .
Face detection has made significant progress after the seminal work by Viola and Jones .
Modern face detectors can easily detect near frontal faces and are widely used in real world applications , such as digital camera and electronic photo album .
Recent research in this area focuses on the unconstrained scenario , where a number of intricate factors .
We propose a WIDER FACE dataset for face detection , which has a high degree of variability in scale , pose , occlusion , expression , appearance and illumination .
We show example images ( cropped ) and annotations .
The annotated face bounding box is denoted in green color .
The WIDER FACE dataset consists of 393 , 703 labeled face bounding boxes in 32 , 203 images ( Best view in color ) .
such as extreme pose , exaggerated expressions , and large portion of occlusion can lead to large visual variations in face appearance .
Publicly available benchmarks such as FDDB , AFW , PASCAL FACE , have contributed to spurring interest and progress in face detection research .
However , as algorithm performance improves , more chal - lenging datasets are needed to trigger progress and to inspire novel ideas .
Current face detection datasets typically contain a few thousand faces , with limited variations in pose , scale , facial expression , occlusion , and background clutters , making it difficult to assess for real world performance .
As we will demonstrate , the limitations of datasets have partially contributed to the failure of some algorithms in coping with heavy occlusion , small scale , and atypical pose .
In this work , we make three contributions .
We introduce a large - scale face detection dataset called WIDER FACE .
It consists of 32 , 203 images with 393 , 703 labeled faces , which is 10 times larger than the current largest face detection dataset .
The faces vary largely in appearance , pose , and scale , as shown in .
In order to quantify different types of errors , we annotate multiple attributes : occlusion , pose , and event categories , which allows in depth analysis of existing algorithms .
We show an example of using WIDER FACE through proposing a multi-scale two - stage cascade framework , which uses divide and conquer strategy to deal with large scale variations .
Within this framework , a set of convolutional networks with various size of input are trained to deal with faces with a specific range of scale .
We benchmark four representative algorithms , either obtained directly from the original authors or reimplemented using open - source codes .
We evaluate these algorithms on different settings and analyze conditions in which existing methods fail .
Related Work
Brief review of recent face detection methods :
Face detection has been studied for decades in the computer vision literature .
Modern face detection algorithms can be categorized into four categories : cascade based methods , part based methods , channel feature based methods , and neural network based methods .
Here we highlight a few notable studies .
A detailed survey can be found in .
The seminal work by Viola and Jones introduces integral image to compute Haar - like features inconstant time .
These features are then used to learn AdaBoost classifier with cascade structure for face detection .
Various later studies follow a similar pipeline .
Among those variants , SURF cascade achieves competitive performance .
Chen et al. learns face detection and alignment jointly in the same cascade framework and obtains promising detection performance .
One of the well - known part based methods is deformable part models ( DPM ) .
Deformable part models define face as a collection of parts and model the connections of parts through Latent Support Vector Machine .
The part based methods are more robust to occlusion compared with cascade - based methods .
A recent study demonstrates state - of - the art performance with just a vanilla DPM ,
achieving better results than more sophisticated DPM variants .
Aggregated channel feature ( ACF ) is first proposed by Dollar et al. to solve pedestrian detection .
Later on , Yang et al . applied this idea on face detection .
In particular , features such as gradient histogram , integral histogram , and color channels are combined and used to learn boosting classifier with cascade structure .
Recent studies show that face detection can be further improved by using deep learning , leveraging the high capacity of deep convolutional networks .
We anticipate that the new WIDER FACE data can benefit deep convolutional network that typically requires large amount of data for training .
Existing datasets :
We summarize some of the well - known face detection datasets in .
AFW , FDDB , and PASCAL FACE
WIDER FACE
Dataset
Overview
To our knowledge , WIDER FACE dataset is currently the largest face detection dataset , of which images are selected from the publicly available WIDER dataset .
We choose 32 , 203 images and label 393 , 703 faces with a high degree of variability in scale , pose and occlusion as depicted in .
WIDER FACE dataset is organized based on 60 event classes .
For each event class , we randomly select 40% / 10 % / 50 % data as training , validation and testing sets .
Here , we specify two training / testing scenarios :
Scenario - Ext : A face detector is trained using any external data , and tested on the WIDER FACE test partition .
Scenario - Int : A face detector is trained using WIDER FACE training / validation partitions , and tested on WIDER FACE test partition .
We adopt the same evaluation metric employed in the PAS - CAL VOC dataset .
Similar to MALF and Caltech datasets , we do not release bounding box ground truth for the test images .
Users are required to submit final prediction files , which we shall proceed to evaluate .
Data Collection
Collection methodology .
WIDER FACE dataset is a subset of the WIDER dataset .
The images in WIDER were collected in the following three steps :
1 ) Event categories were defined and chosen following the Large Scale Ontology for Multimedia ( LSCOM ) , which provides around 1 , 000 concepts relevant to video event analysis .
2 ) Images are retrieved using search engines like Google and Bing .
For each category , 1 , 000 - 3 , 000 images were collected .
3 ) The data were cleaned by manually examining all the images and filtering out images without human face .
Then , similar images in each event category were removed to ensure large diversity in face appearance .
A total of 32 , 203 images are eventually included in the WIDER FACE dataset .
Annotation policy .
We label the bounding boxes for all the recognizable faces in the WIDER FACE dataset .
The bounding box is required to tightly contain the forehead , chin , and cheek , as shown in .
If a face is occluded , we still label it with a bounding box but with an estimation on the scale of occlusion .
Similar to the PASCAL VOC dataset , we assign an ' Ignore ' flag to the face which is very difficult to be recognized due to low resolution and small scale ( 10 pixels or less ) .
After annotating the face bounding boxes , we further annotate the following attributes : pose ( typical , atypical ) and occlusion level ( partial , heavy ) .
Each annotation is labeled by one annotator and cross - checked by two different people . The proposals are generated by using Edgebox .
Y-axis denotes for detection rate .
X-axis denotes for average number of proposals per image .
Lower detection rate implies higher difficulty .
We show histograms of detection rate over the number of proposal for different settings ( a ) Different face detection datasets .
Properties of WIDER FACE
WIDER FACE dataset is challenging due to large variations in scale , occlusion , pose , and background clutters .
These factors are essential to establishing the requirements fora real world system .
To quantify these properties , we use generic object proposal approaches , which are specially designed to discover potential objects in an image ( face can be treated as an object ) .
Through measuring the number of proposals vs. their detection rate of faces , we can have a preliminary assessment on the difficulty of a dataset and potential detection performance .
In the following assessments , we adopt EdgeBox as object proposal , which has good performance in both accuracy and efficiency as evaluated in .
Overall . ( a ) shows that WIDER FACE has much lower detection rate compared with other face detection datasets .
The results suggest that WIDER FACE is a more challenging face detection benchmark compared to exist -.
Histogram of detection rate for different event categories .
Event categories are ranked in an ascending order based on the detection rate when the number of proposal is fixed at 10 , 000 . Top 1 ? 20 , 21 ? 40 , 41 ? 60 event categories are denoted in blue , red , and green , respectively .
Example images for specific event classes are shown .
Y-axis denotes for detection rate .
X-axis denotes for event class name .
ing datasets .
Following the principles in KITTI and MALF datasets , we define three levels of difficulty : ' Easy ' , ' Medium ' , ' Hard ' based on the detection rate of EdgeBox , as shown in the .
The average recall rates for these three levels are 92 % , 76 % , and 34 % , respectively , with 8 , 000 proposal per image .
Scale .
We group the faces by their image size ( height in pixels ) into three scales : small ( between 10 - 50 pixels ) , medium ( between 50 - 300 pixels ) , large ( over 300 pixels ) .
We make this division by considering the detection rate of generic object proposal and human performance .
As can be observed from , the large and medium scales achieve high detection rate ( more than 90 % ) with 8 , 000 proposals per image .
For the small scale , the detection rates consistently stay below 30 % even we increase the proposal number to 10 , 000 .
Occlusion .
Occlusion is an important factor for evaluating the face detection performance .
Similar to a recent study , we treat occlusion as an attribute and assign faces into three categories : no occlusion , partial occlusion , and heavy occlusion .
Specifically , we ask annotator to measure the fraction of occlusion region for each face .
A face is defined as ' partially occluded ' if 1 % - 30 % of the total face area is occluded .
A face with occluded area over 30 % is labeled as ' heavily occluded ' .
shows some examples of partial / heavy occlusions . ( c ) shows that the detection rate decreases as occlusion level increases .
The detection rates of faces with partial or heavy occlusions are below 50 % with 8 , 000 proposals .
Pose . Similar to occlusion , we define two pose deformation levels , namely typical and atypical .
shows some faces of typical and atypical pose .
Face is annotated as atypical under two conditions : either the roll or pitch degree is larger than 30 - degree ; or the yaw is larger than 90 - degree . ( d ) suggests that faces with atypical poses are much harder to be detected .
Event . Different events are typically associated with different scenes .
WIDER FACE contains 60 event categories covering a large number of scenes in the real world , as shown in and .
To evaluate the influence of event to face detection , we characterize each event with three factors : scale , occlusion , and pose .
For each factor we compute the detection rate for the specific event class and then rank the detection rate in an ascending order .
Based on the rank , events are divided into three partitions : easy ( 41 - 60 classes ) , medium ( 21 - 40 classes ) and hard ( 1 - 20 classes ) .
We show the partitions based on scale in .
Partitions based on occlusion and pose are included in the appendix .
Effective training source .
As shown in the
Multi-scale Detection Cascade
Multi - scale detection cascade CNN consists of a set of face detectors , with each of them only deals with faces in a relatively small range of scale .
Each face detector consists of two stages .
The first stage generates multi-scale proposal from a fully - convolutional network .
The second stage gives face and non-face prediction of the candidate windows generate from first stage .
If the candidate window is classified as face , we further refine the location of the candidate window .
Experimental Results
Benchmarks
As we discussed in Sec. 2 , face detection algorithms can be broadly grouped into four representative categories .
For each class , we pick one algorithm as a baseline method .
We select VJ , ACF , DPM , and Faceness as baselines .
The VJ , DPM , and Faceness detectors are either obtained from the authors or from open source library ( OpenCV ) .
The ACF detector is reimplemented using the open source code .
We adopt the Scenario - Ext here ( see Sec. 3.1 ) , that is , these detectors were trained by using external datasets and are used ' as is ' without re-training them on WIDER FACE .
We employ PASCAL VOC evaluation metric for the evaluation .
Following previous work , we conduct linear transformation for each method to fit the annotation of WIDER FACE .
Overall .
In this experiment , we employ the evaluation setting mentioned in Sec. 3.3 .
The results are shown in ( a.1 ) - ( a.3 ) .
Faceness outperforms other methods on three subsets , with DPM and ACF as marginal second and third .
For the easy set , the average precision ( AP ) of most methods are over 60 % , but none of them surpasses 75 % .
The performance drops 10 % for all methods on the medium set .
The hard set is even more challenging .
The performance quickly decreases , with a AP below 30 % for all methods .
To trace the reasons of failure , we examine performance on varying subsets of the data .
Scale .
As described in Sec. 3.3 , we group faces according to the image height : small ( 10 - 50 pixels ) , medium ( 50 - 300 pixels ) , and large ( 300 or more pixels ) scales .
The results of small scale are abysmal : none of the algorithms is able to achieve more than 12 % AP .
This shows that current face detectors are incapable to deal with faces of small scale .
Occlusion .
Occlusion handling is a key performance metric for any face detectors .
In , we show the impact of occlusion on detecting faces with a height of at least 30 pixels .
As mentioned in Sec. 3.3 , we classify faces into three categories : un - occluded , partially occluded ( 1 % - 30 % area occluded ) and heavily occluded ( over 30 % area occluded ) .
With partial occlusion , the performance drops significantly .
The maximum AP is only 26.5 % achieved by Faceness .
The performance further decreases in the heavy occlusion setting .
The best performance of baseline methods drops to 14.4 % .
It is worth noting that Faceness and DPM , which are part based models , already perform relatively better than other methods on occlusion handling .
Pose .
As discussed in Sec. 3.3 , we assign a face pose as atypical if either the roll or pitch degree is larger than 30 degree ; or the yaw is larger than 90 - degree .
Otherwise a face pose is classified as typical .
We show results in .
Faces which are un - occluded and with a scale larger than 30 pixels are used in this experiment .
The performance clearly degrades for atypical pose .
The best performance is achieved by Faceness , with a recall below 20 % .
The results suggest that current face detectors are only capable of dealing with faces with out - of - plane rotation and a small range of in - plane rotation .
Summary .
Among the four baseline methods , Faceness tends to outperform the other methods .
VJ performs poorly on all settings .
DPM gains good performance on medium / large scale and occlusion .
ACF outperforms DPM on small scale , no occlusion and typical pose settings .
However , the overall performance is poor on WIDER FACE , suggesting a large room of improvement .
WIDER FACE as an Effective Training Source
In this experiment , we demonstrate the effectiveness of WIDER FACE dataset as a training source .
We adopt Scenario - Int here ( see Sec. 3.1 ) .
We train ACF and Faceness on WIDER FACE to conduct this experiment .
These two algorithms have shown relatively good performance on WIDER FACE previous benchmarks see ( Sec. 5.1 ) .
Faces with a scale larger than 30 pixels in the training set are used to retrain both methods .
We train the ACF detector using the same training parameters as the baseline ACF .
The negative samples are generated from the training images .
For the Faceness detector , we first employ models shared by the authors to generate face proposals from the WIDER FACE training set .
After that , we train the classifier with the same procedure described in .
We test these models ( denoted as ACF - WIDER and Faceness - WIDER ) on WIDER FACE testing set and FDDB dataset .
WIDER FACE .
As shown in , the retrained models perform consistently better than the baseline models .
The average AP improvement of retrained ACF detector is 5.4 % in comparison to baseline ACF detector .
For the Faceness , the retrained Faceness model obtain 4.2 % improvement on WIDER hard test set .
FDDB .
We further evaluate the retrained models on FDDB dataset .
Similar to WIDER FACE dataset , the retrained models achieve improvement in comparison to the baseline methods .
The retrained ACF detector achieves a recall rate of 87.48 % , outperforms the baseline ACF by a considerable margin of 1.4 % .
The retrained Faceness detector obtains a. Comparison of per class AP .
To save space , we only show abbreviations of category names here .
The event category is organized based on the rank sequence in ( from hard to easy events based on scale measure ) .
We compare the accuracy of Faceness and ACF models retrained on WIDER FACE training set with the baseline Faceness and ACF .
With the help of WIDER FACE dataset , accuracies on 56 out of 60 categories have been improved .
The re-trained Faceness model wins 30 out of 60 classes , followed by the ACF model with 26 classes .
Faceness wins 1 medium class and 3 easy classes .
high recall rate of 91.78 % .
The recall rate improvement of the retrained Faceness detector is 0.8 % in comparison to the baseline Faceness detector .
It worth noting that the retrained Faceness detector performs much better than the baseline Faceness detector when the number of false positive is less than 300 .
Event .
We evaluate the baseline methods on each event class individually and report the results in .
Faces with a height larger than 30 pixels are used in this experiment .
We compare the accuracy of Faceness and ACF models retrained on WIDER FACE training set with the baseline Faceness and ACF .
With the help of WIDER FACE dataset , accuracies on 56 out of 60 event categories have been improved .
It is interesting to observe that the accuracy obtained highly correlates with the difficulty levels specified in Sec. 3.3 ( also refer to ) .
For example , the best performance on " Festival " which is assigned as a hard class is no more than 46 % AP .
Evaluation of Multi-scale Detection Cascade
In this experiment we evaluate the effectiveness of the proposed multi-scale cascade algorithm .
Apart from the ACF - WIDER and Faceness - WIDER models ( Sec. 5.2 ) , we establish a baseline based on a " Two - stage CNN " .
This model differs to our multi-scale cascade model in the way it handles multiple face scales .
Instead of having multiple networks targeted for different scales , the two - stage CNN adopts a more typical approach .
Specifically , its first stage consists only a single network to perform face classification .
During testing , an image pyramid that encompasses different scales of a test image is fed to the first stage to generate multi -scale face proposals .
The second stage is similar to our multi-scale cascade model - it performs further refinement on proposals by simultaneous face classification and bounding box regression .
We evaluate the multi-scale cascade CNN and baseline methods on WIDER Easy / Medium / Hard subsets .
As shown in , the multi-scale cascade CNN obtains 8.5 % AP improvement on the WIDER Hard subset compared to the retrained Faceness , suggesting its superior capability in handling faces with different scales .
In particular , having multiple networks specialized on different scale range is shown effective in comparison to using a single network to handle multiple scales .
In other words , it is difficult fora single network to handle large appearance variations caused by scale .
For the WIDER Medium subset , the multi-scale cascade CNN outperforms other baseline methods with a considerable margin .
All models perform comparably on the WIDER Easy subset .
Conclusion
We have proposed a large , richly annotated WIDER FACE dataset for training and evaluating face detection algorithms .
We benchmark four representative face detection methods .
Even considering an easy subset ( typically with faces of over 50 pixels height ) , existing state - of - the - art algorithms reach only around 70 % AP , as shown in .
With this new dataset , we wish to encourage the community to focusing on some inherent challenges of face detection - small scale , occlusion , and extreme poses .
These factors are ubiquitous in many real world applications .
For instance , faces captured by surveillance cameras in public spaces or events are typically small , occluded , and atypical poses .
These faces are arguably the most interesting yet crucial to detect for further investigation .
Appendix
Training Multi-scale Proposal Network
We provide details of the training process for multi-scale proposal networks .
In this step , we train four fully convolutional networks for face classification and scale classification .
The network structures are summarized in , we initialize the layers from Conv 1 to Conv 5 using the Imagenet 1 , 000 categories pre-trained Clarifai net .
For the Proposal Network 4 , we initialize the layers from Conv 2 to Conv 5 using pre-trained Clarifai net .
The remaining layers in each network are randomly initialized with weights drawn from a Gaussian distribution of = 0 and ? = 0.01 .
To account for the multi-label scenario , cross - entropy loss is adopted as shown below :
( y i log p ( y i | I i ) + ( 1 ? y i ) log ( 1 ? p ( y i | I i ) ) ) , and
Back propagation and SGD are also employed here for optimizing Eqn.. Similar to , we set the initial finetuning learning rate as one - tenth of the corresponding pretraining learning rate and drop it by a factor of 10 throughout training .
After training , we conduct hard negative mining on the training set and further tune the proposal networks using hard negative samples .
Training Face Detector
In this section , we provide more details of the training process for face detection .
As mentioned at beginning , we train .
Histogram of detection rate for different event categories .
Event categories are ranked based on detection rate when number of proposal is 10 , 000 in the ascending order .
Top 1 ? 20 , 21 ? 40 , 41 ? 60 event categories are denote in blue , red , green respectively .
Example images for specific event class are shown .
Y-axis denotes for detection rate .
X-axis denotes for event class name ..
Full name of abbreviation of event categories .
