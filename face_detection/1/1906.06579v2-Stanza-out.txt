title
EXTD : Extremely Tiny Face Detector via Iterative Filter Reuse
abstract
In this paper , we propose a new multi-scale face detector having an extremely tiny number of parameters ( EXTD ) , less than 0.1 million , as well as achieving comparable performance to deep heavy detectors .
While existing multiscale face detectors extract feature maps with different scales from a single backbone network , our method generates the feature maps by iteratively reusing a shared lightweight and shallow backbone network .
This iterative sharing of the backbone network significantly reduces the number of parameters , and also provides the abstract image semantics captured from the higher stage of the network layers to the lower - level feature map .
The proposed idea is employed by various model architectures and evaluated by extensive experiments .
From the experiments from WIDER FACE dataset , we show that the proposed face detector can handle faces with various scale and conditions , and achieved comparable performance to the more massive face detectors that few hundreds and tens times heavier in model size and floating point operations .
Introduction
Detecting faces in an image is considered to be one of the most practical tasks in computer vision applications , and many studies are proposed from the beginning of the computer vision research .
After the advent of deep neural networks , many face detection algorithms applying the deep network have reported significant performance improvement to the conventional face detectors .
The state - of - the - art ( SOTA ) face detectors for in - the - wild images employ the framework of the recent object detectors .
These methods can even handle a various scale of faces with difficult conditions such as distortion , rotation , and occlusion .
Among them , the face detectors using multiple feature - maps from different layer locations , which mainly stem from , are dominantly used since * Clova AI Research , NAVER Corp .
We follow the alphabetical order except the first author .
Our method ( star ) shows comparable mAP to S3FD with a significantly smaller model .
Red stars denote the proposed models with various sizes .
' S3FD + M ' denotes the S3FD variation using MobileFaceNet as a backbone network instead of VGG - 16 .
Best viewed in wide and colored vision .
these methods can handle the faces with various scale in a single forward path .
While these methods achieved impressive detection performance , they commonly share two problems .
One is their large number of parameters .
Since they use a large classification network such as VGG - 16 , ResNet - 50 or 101 , and DenseNet - 169 , the number of total parameters exceed 20 million , over 80 Mb supposing 32 - bit floating point for each parameter .
Furthermroe , the amount of floating point operations ( FLOPs ) also exceeds 100G , and these make it nearly impossible to use the face detectors in CPU or mobile environment , where the most face applications run in .
The second problem , from the architecture perspective , is the limited capacity of the low - level feature map in capturing object semantics .
The most single - shot detector ( SSD ) variant object and face detectors struggle the problem because the low - level feature map passes shallow convolutional layers .
To alleviate the problem , the variants of Feature pyramid network ( FPN ) architecture such as are used but requires additional parameters and memories for re-expanding the feature map .
In this paper , we propose a new multi-scale face detector with extremely tiny size ( EXTD ) resolving the two mentioned problems .
The main discovery is that we can share the network in generating each feature - map , as shown in .
As in the figure , we design a backbone network such that reduces the size of the feature map by half , and we can get the other feature maps with recurrently passing the network .
The sharing can significantly reduce the number of parameters , and this enables our model to use more layers to generate the low - level feature maps used for detecting small faces .
Also , the proposed iterative architecture makes the network to observe the features from various scale of faces and from various layer locations , and hence offer abundant semantic information to the network , without adding additional parameters .
Our baseline framework follows FPN - like structures , but can also be applied to SSD - like architecture .
For SSD based architecture , we adopt the setting from .
For the FPN architectures , we refer an up - sampling strategy from .
The backbone network is designed to have less than 0.1 million parameters with employing inverted residual blocks proposed in MobileNet - V2 .
We note that our model does not require any extra layer commonly defined as in , and is trained from scratch .
We evaluated the proposed detector and its variants on WIDER FACE dataset , the most widely used and similar to the in - the - wild situation .
The main contributions of this work can be summarized as follows :
We propose an iterative network sharing model for multi-stage face detection which can significantly reduce the parameter size , as well as provide abundant object semantic information to the lower stage feature maps .
( 2 ) We design a lightweight backbone network for the proposed iterative feature map generation with 0.1 M number of parameters , which less than 400 Kb , and achieved comparable mAP to the heavy face detection methods .
( 3 ) We employ the iterative network sharing idea to the widely used detection architectures , FPN and SSD , and show the effectiveness of the proposed scheme .
Related Works
Face detectors :
Face detection has been an important research topic since an initial stage of computer vision researches .
Viola et al .
proposed a face detection method using Haar features and Adaboost with decent performance , and several different approaches followed .
After deep learning has become dominant , many face detection methods applying the techniques have been published .
In the early stages , various attempts were tried to employ the deep architecture to face detection , such as cascade architecture , and occlusion handling .
Recent face detectors has been designed based on the architecture of generic object detectors including Faster - RCNN , R - FCN , SSD , FPN , and Reti - na Net .
Face RCNN and its variants apply Faster - RCNN , and use R - FCN for detecting faces with meaningful performance improvements .
Also , to cope with the various scale of faces with single forward path , object detectors such as SSD , RetinaNet , and FPN are dominantly adopted since they use features from multiple layer locations for detecting objects with various scale in a single forward path .
S3FD achieved promising performance by applying SSD with introducing multiple strategies to handle the small size of faces .
FAN uses Retina
Net by applying anchor level attention to detect the occluded faces .
After S3FD , many improved versions are introduced and achieved performance gain from the previous methods .
FPN based face detection methods achieved SOTA performance by enhancing the expression capacity of the lower - level feature map used for detecting small faces .
The mentioned SOTA methods commonly use classification network such as VGG - 16 , ResNet - 50 or 101 , and DenseNet - 169 as a backbone of the model .
These classification networks have a large number of parameters exceeding 20 million , and the model size is over 80 Mb supposing 32 - bit floating point for each parameter .
Some cascade methods such as report decent m AP with the smaller mount of model size , about 3.8 Mb .
However , the size is still burdensome to the devices like mobile , because users generally want their applications not to exceed few ten 's of Mb. Also , the face detector should mostly be much smaller than the total size of the application because a face detector is usually an end - level function of the application .
Here , we propose a new scheme of iteratively sharing the backbone network , which can be applicable to both SSD and FPN based architectures .
The method achieves comparable accuracy to the original models , and the overall model size is extremely smaller as well .
Lightweight generic object detectors :
Recently , for detecting general objects in condition with a limited resource such as mobile devices , various single - stage , and two - stage lightweight detectors were proposed .
For the single - stage detectors , MobileNet - SSD , MobileNetV2 - SSDLite , Pelee and Tiny - DSOD were proposed .
For two - stage detectors , Light - Head R - CNN and Thunder Net were proposed .
The mentioned methods achieved meaningful accuracy and size trade - off , but we aim to develop a detector which has a much smaller number of parameters with introducing a new paradigm , iterative use of the backbone network .
Recurrent convolutional network :
The idea of recurrently using convolutional layers has been applied to various computer vision applications .
Sharesnet and Iamnn applied recurrent residual network into classification task .
Guo et al .
reduce the parameters by sharing depthwise convolutional filters in learning multiple visual domain data .
The iterative sharing is also applied to dynamic routing , fast inference of video , feature transfer , super-resolution , and recently in segmentation .
In this paper , we introduce a method applying the concept of iterative convolutional layer sharing in the face detection task , which is the first to the best of our knowledge .
EXTD
In this section , we introduce the main components of the proposed work including iterative feature map generation , the architectures of the proposed face detection models , backbone networks , and classification and regression head design .
Also , implementation details for designing and training the models will be introduced .
shows the overall framework of the proposed method with two variations , SSD - like , and FPN - like frameworks .
In the proposed method , we get multiple feature maps with different resolutions by recurrently passing the backbone network .
Let assume that F ( ) and E ( ) each denotes the backbone network and the first Conv layer with stride two .
Then , the iterative process is defined as follows :
Iterative Feature Map Generation
Here , the set {f 1 , .. , f N } denote the set of feature maps , and x is the image .
In FPN version , we upsample each feature map and connect the previous feature maps via skipconnection .
The upsampling step U i ( ) is conducted with bilinear upsampling followed by an upsampling block composed of separable convolution and point - wise convolution , inspired by .
The resultant set of the feature map G = {g 1 , ... , g N } is obtained as ,
For the SSD - like architecture , which is the first variant , we extract feature maps f i and connect the classification and regression head to the feature maps .
In FPN - like architecture , the feature maps g i from equation are used .
The classification and regression heads are designed by a 3x3 convolutional network and hence , both models are designed as a fully convolutional network .
This enables the models to deal with various size of images .
The detailed implementation of the heads is introduced in below sections .
For all the cases , we set the image x to have 640x640 resolution in training phase and use N = 6 number of feature maps .
Hence , we get 160x160 , 80x80 , 40x40 , 20x20 , 10x10 and 5 x 5 resolution feature maps .
In each location of the feature map , prior anchor candidates for the face is defined , following the same setting as S3FD .
One notable property of this architecture is that this method provides more abundant semantic information in lower - level feature maps compared to the face detectors adopting SSD architecture .
While the existing methods commonly report the problem that the lower - level feature maps only contain limited semantic information due to their limited length of depth , our iterative architecture repeatedly shows intermediate level features and the various scale of faces to the network .
We conjecture that the different features have similar semantics because the target objects in our case are faces , and the faces share homogeneous shapes regardless of their scale dissimilar to general objects .
In Section 4 , we show that the proposed method clearly enhances the detection accuracy for small size faces , and this can be more improved by taking the FPN architecture .
Model Component Description
In the proposed model , a lightweight backbone network reducing the feature map resolution by half is used .
The network is composed of inverted residual blocks followed by one 3x3 convolutional ( Conv ) filter with stride 2 , based on .
The inverted residual block is composed of a set of point - wise Conv , separable Conv , and point - wise Conv .
In each block , the channel width is expanded in the first point - wsie Conv and then , squeezed by the last point - wise Conv filter .
The default setting of the network depth is set to 6 or 8 , and the output channel width is set to 32,48 or 64 , which do not largely exceed overall 0.1 million parameters .
Different from MobileNet - V2 , PReLU ( or leaky - ReLU ) is applied and shown to be more successful than ReLU in training the proposed recurrent architecture .
This phenomenon will be further discussed in Section 4 .
Other than the inverted residual block , the proposed architecture also includes feature extraction block , upsampling blocks , and classification and regression heads .
The detailed description of the components is introduced in 3 .
The figures in ( a ) and ( b ) each shows the inverted residual block architecture .
Residual skip - connection is applied when the input and output channel width are equivalent , and at the same time , the stride is set to one .
The upsampling block in ( c ) consists of bilinear upsample layer followed by depth - wise and point - wise Conv blocks .
Fea -ture extraction block ( d ) is defined by a 3 x3 Conv network followed by batch normalization and the activation function .
The classification ( e ) and regression ( f ) heads are also defined by a 3 x3 Conv network .
The implementation of the head is described in Section 3.3 .
Classification and Regression Head Design
For detecting the faces using the generated feature maps , we use a classification head and a regression head for each feature map to classify whether each prior box contains a face , and to regress the prior box to the exact location .
The classification and regression heads are both defined as single 3 x3 Conv filters as shown in .
The classification head Ci has two - dimensional output channel c i except C 1 that having four - dimensional channels .
For C 1 , we apply Maxout approach to select two of the four channels for alleviating the false positive rate of the small faces , as introduced in S3FD .
The regression head R i is defined to have output feature r i to have four - dimensionional channel , and each denotes width , height ratio , and center locations , adopting the dominantly used setting in RPN .
Training
The proposed backbone network and the classification and regression head are jointly trained by a multitask loss function from RPN composed of a classification loss l c and a regression loss l r as ,
Here , j is the index of the anchor boxes , and the label c * j ?
{ 0 , 1 } and r * j is the ground truth of the anchor box .
The label c * j is set to 1 when Jaccard overlap between the anchor box and ground trurh box is higher than a threshold t.
The denominator N cls denotes the total number of positive and negative samples .
The regression loss is computed only for the positive sample and hence , the number N reg is defined by N reg = j c * j .
The parameter ?
is defined to balance the two losses because N cls and N reg are different from each other .
The vector r * j denotes the ground truth box location and size for the face .
The classification loss l c and the regression loss l rare defined as cross -entropy loss and smooth - 1 loss , respectively .
The primary obstacle for the classification in the face detection task is a class imbalance problem between the face and the background , especially regarding the small faces .
To alleviate the problem , we also adopt the strategies including online hard negative mining and scale compensation anchor matching introduced in S3FD .
Using the hard negative mining technique , we balance the ratio of positive and negative samples N neg / N pos to 3 and the balancing parameter ?
is set to 4 .
Also , from the scale compensation anchor matching strategy , we first pick the positive samples where the Jaccard overlap is over 0.35 , and then further pick the remaining samples in sorted order from the samples that their Jaccard overlap is larger than 0.1 if the number of positive samples is insufficient .
For Data augmentation , we follow the conventional augmentation setting from S3FD .
The augmentation includes color distortions , random crop , horizontal flip , and vertical flip .
The proposed method is implemented with PyTorch and NAVER Smart Machine Learning ( NSML ) system .
Please refer Appendix A to seethe detailed training and optimization settings for training the proposed network .
Code will be available at https ://github.com/clovaai.
Experiments
In this section , we quantitatively and qualitatively analyze the proposed method with various ablations .
For the quantitative analysis , we compare the detection performance of the proposed method and the SOTA face detection algorithms .
Qualitatively , we show that our method can successfully detect faces in various conditions .
Experimental Setting
Datasets : we tested the proposed method and ablations of the method with WIDER FACE dataset , which is most recent and is similar to in - the - wild face detection situation .
The images in the dataset are divided into Easy , Medium , and Hard cases which are roughly categorized by different scales : large , medium , and small , of faces .
The Hard case includes all the images of the dataset , and the Easy and Medium cases both are the subsets of the Hard case .
The dataset has total 32,203 images with 393,703 labeled faces and is split into training ( 40 % ) , validation ( 20 % ) and testing ( 40 % ) set .
We trained the detectors with the training set and evaluated them with validation and test sets .
Comparison :
Since our method followed the training and implementation details such as anchor design , data augmentation , and feature - map resolution design equivalent to S3FD , which has become one of the baseline methods in face detection field , we mostly evaluated the performance by comparing the S3FD model and its SOTA variations .
The other techniques based on the S3FD model such as Pyramid anchor , Feature enhancement module , Improved anchor matching , and Progressive anchor loss would be able to be adapted to the proposed model without revising the proposed structure .
Also , we used the MobileFaceNet , the face variant of the MobileNet - V2 , to the S3FD model instead of VGG - 16 to seethe effectiveness of the proposed method compared to the case of using the lightweight backbone network .
Variations :
We applied the proposed recurrent scheme mainly into the FPN - based structure .
For the model , we designed three variations which have a different number of parameters , lighter one having 0.063 M parameters with 32 channels for each feature maps , intermediate one having 0.1 M parameters with 48 channels , and the heavier one with 64 channels and 0.16M parameters when designed as FPN .
See Appendix
B for the detailed configuration of the backbone networks for each case .
Also , we tested different activation functions : ReLU , PReLU , and Leaky - ReLU for each model .
The negative slope of the Leaky - ReLU is set to 0.25 , which is identical to the initial negative slope of the PReLU .
In the following section , we will term each variation by a combination of abbreviations ; EXTD - model - channel - activation .
For example , the term EXTD - FPN - 32 - PReLU denotes the proposed model combined with FPN , with feature channel width 32 and with activation function PReLU .
As an ablation , we also applied the proposed recurrent backbone into SSD - like structure as well .
The ablation was trained and tested with the same conditions to the FPNbased version and abbreviated as SSD .
Same as FPN case , for example , the term EXTD - SSD - 32 - PReLU denotes the proposed model combined with SSD , with feature channel width 32 and with activation function PReLU .
Performance Analysis
In , we list the quantitative evaluation results of face detection in WIDER FACE dataset and the comparison to the SOTA face detectors .
The table shows the m AP of the models on Easy , Medium , Hard cases for both validation and test sets of the dataset .
Also , the table includes model information such as their backbone networks , number of parameters , and total number of adder arithmetics ( Madds ) .
In , the precision recall curve for the proposed and the other methods are presented .
shows the examples of the face detection results from images with various conditions .
In , we evaluate the latency of the models in terms of the resolution of images , which measured via a machine with CPU i 7 core and NVIDIA TITAN - X .
For a fair comparison , all the inference processes of the models are implemented by PyTorch 1.0 .
Comparison to the Existing Methods :
The results in 138 times lighter in model size and are 28.3 , 19.2 , and 11 times lighter in Madds .
When compared to SOTA face detectors such as Pyra - midBox and DSFD , our best model EXTD - FPN - 64 - PReLU achieved lower results .
The margin between PyramidBox and the proposed model on WIDER FACE hard case was 3.4 % .
Considering that PyramidBox inherits from S3FD and our model follows the equivalent training and detection setting to S3FD , our model would have a possibility to further increase the detection performance by adding the schemes proposed in Pyramid Box .
The m AP gap to DSFD , which is tremendously heavier , is about 5.0 % , but it would be safe to suggest that the proposed method offers more decent trade - off in that DSFD uses about 2860 times more parameters than the proposed method .
This is also meaningful result in that our method did not use any kind of pre-training of the backbone network using the other dataset such as Image Net.
shows the ROC curves of the proposed EXTD - FPN - 64 - PReLU and the other methods .
From the graphs , we can see that our method is included in the SOTA group of the detectors using heavyweight pre-trained backbone networks .
When it comes to our SSD - based variations , they got lower mAP results than FPN - based variants .
However , when compared with the S3FD version trained with Mo - bile FaceNet backbone network , the proposed SSD variants achieved comparable or better detection performance .
It is a meaningful result in that the proposed variations have smaller feature map width , S3FD - Mobile Face Net holds feature map size of , and use the smaller number of layer blocks ; inverted residual blocks same as MobileFaceNet , repeatedly .
This shows that the proposed itertative scheme efficiently reduces the number of parameters without loss of accuracy .
Also , from the graph in , we showed that our EXTD achieved faster inference speed to the S3FD , which is considered as real - time face detector , in a wide range of an input image resolution .
This shows that the proposed face detector can safely alter S3FD without losing accuracy and with consuming much smaller capacity , as well as maintaining the inference speed .
It is interesting to note that the inference was much slow when using MobileFaceNet instead of VGG - 16 .
It would mainly be due to that Mobile - FaceNet version should pass more filters ( 48 ) than VGG - 16 version , and the inference times of the filters including pooling , depth - wise , point - wise and ordinary convolutional filters are not that different in Pytorch implementation .
Detection performance regarding the Face Scale :
One notable characteristic of the proposed method captured from the evaluation is that our detector obtained better performance when dealing with a small size of faces .
From the table , we can see that our method achieved higher performance in WIDER FACE hard dataset than other cases .
Since the Easy and Medium cases are subsets of the Hard dataset , this means that the proposed method is especially fitted to capture small sized faces .
This tendency is commonly observed for different variations , for the different model architecture , and for the different channel widths .
This supports the proposition suggested in Section 3.1 that the proposed recurrent structure strengthens the feature map , especially for the lower - level feature maps , and hence enhance the detection performance of the small faces .
Variation Analysis
The evaluation on the variations of the proposed EXTD is summarized in The value in the parentheses shows the margin between the best model in the block ( written in boldface ) .
Effect of the Model Architecture :
From the table , we can find two common observations among the proposed variations .
First , for all the different channel width , FPN based architecture achieved better detection performance compared to SSD based architecture , especially for detecting small faces .
The idea of expanding the number of layers for reaching the largest sized feature - map , for detecting the smallest size of objects , is a common strategy for SSD variant methods .
This approach assumes that typical SSD structure passes too small number of layers and hence , the resultant feature - map could not import much information useful for the detection task .
In the face detection task , this assumption seems to be correct in that the FPN based models notably achieved superior detection performance on small faces compared to SSD based models for all the cases .
Second , for both SSD based and FPN based model , channel width was another key factor for performance enhancement .
As the channel width increased by 32 to 64 , we can see that the detection accuracy significantly enhanced for all the cases ; Easy , Medium , and Hard .
Considering that we used a smaller number of layers for 48 and 64 channel cases than the case with 32 channel , this shows that having enough size of channel width is critical for embedding sufficient information to the feature map for detecting faces .
Effect of the Activation functions :
From the evaluation , we found that the choice of the activation function is another factor governing the detection performance of the proposed method .
In all the cases including FPN based and SSD based structures , PReLU was the most effective choice when it comes to mAP , but the gap between Leaky - ReLU was not that significant for the FPN variants .
When tested with SSD based architecture , PReLU outperformed Leaky - ReLU with larger margin than those using FPN structure .
It is worth noting that ReLU occurred notable performance decreases especially when the channel width was small for both SSD and FPN cases .
When the channel width was set to 32 , m AP for all the three cases were lower than 10 % to 20 % compared to those using other activation functions .
The decreases were alleviated as the channel width increased .
When the channel width was 48 , the gap was about 2.2 % , and in the channel width 64 case , the margin was about 1.2 % .
From the results , we conjecture that the nature of ReLU that set all the negative values to zero occurs information loss in the proposed iterative process since it makes the feature map too sparse , and this information loss would be much critical when the channel width is small .
Conclusion
In this paper , we proposed a new face detector which significantly reduces the model sizes as well as maintaining the detection accuracy .
By re-using backbone network layers recurrently , we reduced the vast amount of the network parameters and also obtained comparable performance to recent deep face detection methods using heavy backbone networks .
We showed that our methods achieved very close mAP to the baseline S3 FD only with hundreds time smaller parameters and with using tens time smaller Madd without using pre-training .
We expect that our method can be further improved by applying recent techniques of the SOTA detectors which integrated to S3FD .
Appendix A. Implementation detail
For training the proposed architecture , a stochastic gradient descent optimizer ( SGD ) with learning rate 1e ? 3 , with 0.9 momentum , 0.0005 weight decay , and batch size 16 is used .
The training is conducted from scratch , and the network weights were initialized with He-method .
The maximum iteration number is basically set to 240K , and we drop the learning rate to 1e ? 4 and 1e ? 5 at 120 K and 180K iterations .
Also , we test the architecture with twice larger iterations 480 K as well .
In this case , the learning rate is dropped at 240 K and 360K iterations .
Similar to the other networks using depth - wise separable networks , further performance improvements were observed when training the network with larger iteration .
