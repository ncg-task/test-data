title

abstract

narrative
?Abstract-Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this paper, we propose a deep cascaded multi-task framework which exploits the inherent correlation between them to boost up their performance. In particular, our framework adopts a cascaded structure with three stages of carefully designed deep convolutional networks that predict face and landmark location in a coarse-to-fine manner. In addition, in the learning process, we propose anew online hard sample mining strategy that can improve the performance automatically without manual sample selection. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging FDDB and WIDER FACE benchmark for face detection, and AFLW benchmark for face alignment, while keeps real time performance.

Index Terms-Face detection, face alignment, cascaded convolutional neural network

I. INTRODUCTION
ACE detection and alignment are essential to many face applications, such as face recognition and facial expression analysis. However, the large visual variations of faces, such as occlusions, large pose variations and extreme lightings, impose great challenges for these tasks in real world applications.
The cascade face detector proposed by Viola and Jones utilizes Haar-Like features and AdaBoost to train cascaded classifiers, which achieve good performance with real-time efficiency. However, quite a few works indicate that this detector may degrade significantly in real-world applications with larger visual variations of human faces even with more advanced features and classifiers. Besides the cascade structure, introduce deformable part models (DPM) for face detection and achieve remarkable performance. However, they need high computational expense and may usually require expensive annotation in the training stage. Recently, convolutional neural networks (CNNs) achieve remarkable progresses in a variety of computer vision tasks, such as image classification and face recognition. Inspired by the good per-K.-P. formance of CNNs in computer vision tasks, some of the CNNs based face detection approaches have been proposed in recent years. Yang et al. train deep convolution neural networks for facial attribute recognition to obtain high response in face regions which further yield candidate windows of faces. However, due to its complex CNN structure, this approach is time costly in practice. Li et al. use cascaded CNNs for face detection, but it requires bounding box calibration from face detection with extra computational expense and ignores the inherent correlation between facial landmarks localization and bounding box regression.
Face alignment also attracts extensive interests. Regression-based methods and template fitting approaches are two popular categories. Recently, Zhang et al. proposed to use facial attribute recognition as an auxiliary task to enhance face alignment performance using deep convolutional neural network.
However, most of the available face detection and face alignment methods ignore the inherent correlation between these two tasks. Though there exist several works attempt to jointly solve them, there are still limitations in these works. For example, Chen et al. jointly conduct alignment and detection with random forest using features of pixel value difference. But, the handcraft features used limits its performance. Zhang et al. use multi-task CNN to improve the accuracy of multi-view face detection, but the detection accuracy is limited by the initial detection windows produced by a weak face detector.
On the other hand, in the training process, mining hard samples in training is critical to strengthen the power of detector. However, traditional hard sample mining usually performs an offline manner, which significantly increases the manual operations. It is desirable to design an online hard sample mining method for face detection and alignment, which is adaptive to the current training process automatically.
In this paper, we propose anew framework to integrate these two tasks using unified cascaded CNNs by multi-task learning. The proposed CNNs consist of three stages. In the first stage, it produces candidate windows quickly through a shallow CNN. Then, it refines the windows to reject a large number of non-faces windows through a more complex CNN. Finally, it uses a more powerful CNN to refine the result and output facial landmarks positions. Thanks to this multi-task learning framework, the performance of the algorithm can be notably improved. The major contributions of this paper are summarized as follows:

II. APPROACH
In this section, we will describe our approach towards joint face detection and alignment.

A. Overall Framework
The overall pipeline of our approach is shown in. Given an image, we initially resize it to different scales to build an image pyramid, which is the input of the following three-stage cascaded framework:
Stage 1: We exploit a fully convolutional network[?], called Proposal Network (P-Net), to obtain the candidate windows and their bounding box regression vectors in a similar manner as. Then we use the estimated bounding box regression vectors to calibrate the candidates. After that, we employ non-maximum suppression (NMS) to merge highly overlapped candidates.
Stage 2: all candidates are fed to another CNN, called Refine Network (R-Net), which further rejects a large number of false candidates, performs calibration with bounding box regression, and NMS candidate merge.

Stage 3:
This stage is similar to the second stage, but in this stage we aim to describe the face in more details. In particular, the network will output five facial landmarks' positions.

B. CNN Architectures
In, multiple CNNs have been designed for face detection. However, we noticed its performance might be limited by the following facts: (1) Some filters lack diversity of weights that may limit them to produce discriminative description. Compared to other multi-class objection detection and classification tasks, face detection is a challenge binary classification task, so it may needless numbers of filters but more discrimination of them. To this end, we reduce the number of filters and change the 5×5 filter to a 3×3 filter to reduce the computing while increase the depth to get better performance. With these improvements, compared to the previous architecture in, we can get better performance with less runtime (the result is shown in. For fair comparison, we use the same data for both methods). Our CNN architectures are showed in.

C. Training
We leverage three tasks to train our CNN detectors: face/non-face classification, bounding box regression, and facial landmark localization. 1) Face classification: The learning objective is formulated as a two-class classification problem. For each sample , we use the cross-entropy loss: where is the probability produced by the network that indicates a sample being a face. The notation denotes the ground-truth label.
2) Bounding box regression: For each candidate window, we predict the offset between it and the nearest ground truth (i.e., the bounding boxes' left top, height, and width). The learning objective is formulated as a regression problem, and we employ the Euclidean loss for each sample :
where ? regression target obtained from the network and is the ground-truth coordinate. There are four coordinates, including left top, height and width, and thus . 3) Facial landmark localization: Similar to the bounding box regression task, facial landmark detection is formulated as a regression problem and we minimize the Euclidean loss:
where ? is the facial landmark's coordinate obtained from the network and is the ground-truth coordinate. There are five facial landmarks, including left eye, right eye, nose, left mouth corner, and right mouth corner, and thus . 4) Multi-source training: Since we employ different tasks in each CNNs, there are different types of training images in the learning process, such as face, non-face and partially aligned face. In this case, some of the loss functions (i.e., Eq. (1)-(3) ) are not used. For example, for the sample of background region, we only compute , and the other two losses are set as 0. This can be implemented directly with a sample type indicator. Then the overall learning target can be formulated as:
where is the number of training samples. denotes on the task importance. We use in P-Net and R-Net, while in O-Net for more accurate facial landmarks localization.
is the sample type indicator. In this case, it is natural to employ stochastic gradient descent to train the CNNs. 5) Online Hard sample mining: Different from conducting traditional hard sample mining after original classifier had been trained, we do online hard sample mining in face classification task to be adaptive to the training process.
In particular, in each mini-batch, we sort the loss computed in the forward propagation phase from all samples and select the top 70% of them as hard samples. Then we only compute the gradient from the hard samples in the backward propagation phase. That means we ignore the easy samples that are less helpful to strengthen the detector while training. Experiments show that this strategy yields better performance without manual sample selection. Its effectiveness is demonstrated in the Section III.

III. EXPERIMENTS
In this section, we first evaluate the effectiveness of the proposed hard sample mining strategy. Then we compare our face detector and alignment against the state-of-the-art methods in Face Detection Data Set and Benchmark (FDDB), WIDER FACE, and Annotated Facial Landmarks in the Wild (AFLW) benchmark. FDDB dataset contains the annotations for 5,171 faces in a set of 2,845 images. WIDER FACE dataset consists of 393,703 labeled face bounding boxes in 32,203 images where 50% of them for testing into three subsets according to the difficulty of images, 40% for training and the remaining for validation. AFLW contains the facial landmarks annotations for 24,386 faces and we use the same test subset as. Finally, we evaluate the computational efficiency of our face detector.

A. Training Data
Since we jointly perform face detection and alignment, here we use four different kinds of data annotation in our training process: (i) Negatives: Regions that the Intersection-over-Union (IoU) ratio less than 0.3 to any ground-truth faces; (ii) Positives: IoU above 0.65 to aground truth face; (iii) Part faces: IoU between 0.4 and 0.65 to aground truth face; and (iv) Landmark faces: faces labeled 5 landmarks' positions. Negatives and positives are used for face classification tasks, positives and part faces are used for bounding box regression, and landmark faces are used for facial landmark localization. The training data for each network is described as follows: 1) P-Net: We randomly crop several patches from WIDER FACE to collect positives, negatives and part face. Then, we crop faces from CelebA as landmark faces 2) R-Net: We use first stage of our framework to detect faces from WIDER FACE to collect positives, negatives and part face while landmark faces are detected from CelebA.
3) O-Net: Similar to R-Net to collect data but we use first two stages of our framework to detect faces.

B. The effectiveness of online hard sample mining
To evaluate the contribution of the proposed online hard sample mining strategy, we train two O-Nets (with and without online hard sample mining) and compare their loss curves. To make the comparison more directly, we only train the O-Nets for the face classification task. All training parameters including the network initialization are the same in these two O-Nets. To compare them easier, we use fix learning rate. shows the loss curves from two different training ways. It is very clear that the hard sample mining is beneficial to performance improvement.

C. The effectiveness of joint detection and alignment
To evaluate the contribution of joint detection and alignment, we evaluate the performances of two different O-Nets (joint facial landmarks regression task and do not joint it) on FDDB (with the same P-Net and R-Net for fair comparison). We also compare the performance of bounding box regression in these two O-Nets. suggests that joint landmarks localization task learning is beneficial for both face classification and bounding box regression tasks.

D. Evaluation on face detection
To evaluate the performance of our face detection method, we compare our method against the state-of-the-art methods in FDDB, and the state-of-the-art methods in WIDER FACE. (a)-(d) shows that our method consistently outperforms all the previous approaches by a large margin in both the benchmarks. We also evaluate our approach on some challenge photos 1 .

E. Evaluation on face alignment
In this part, we compare the face alignment performance of our method against the following methods: RCPR, TSPM, Luxand face SDK, ESR, CDM, SDM, and TCDCN. In the testing phase, there are 13 images that our method fails to detect face. So we crop the central region of these 13 images and treat them as the input for O-Net. The mean error is measured by the distances between the estimated Examples are showed in http://kpzhang93.github.io/SPL/index.html landmarks and the ground truths, and normalized with respect to the inter-ocular distance. (e) shows that our method outperforms all the state-of-the-art methods with a margin.

F. Runtime efficiency
Given the cascade structure, our method can achieve very fast speed in joint face detection and alignment. It takes 16fps on a 2.60GHz CPU and 99fps on GPU (Nvidia Titan Black). Our implementation is currently based on un-optimized MATLAB code.

IV. CONCLUSION
In this paper, we have proposed a multi-task cascaded CNNs based framework for joint face detection and alignment. Experimental results demonstrate that our methods consistently outperform the state-of-the-art methods across several challenging benchmarks (including FDDB and WIDER FACE benchmarks for face detection, and AFLW benchmark for face alignment) while keeping real time performance. In the future, we will exploit the inherent correlation between face detection and other face analysis tasks, to further improve the performance.