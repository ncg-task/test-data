257	43	74	http://github.com/dalab/deep-ed
179	15	29	implemented in
179	34	49	Torch framework
181	0	3	For
181	4	26	entity embeddings only
181	32	35	use
181	36	65	Wikipedia ( Feb 2014 ) corpus
181	66	69	for
181	70	78	training
182	0	14	Entity vectors
182	19	39	initialized randomly
182	40	44	from
182	47	73	0 mean normal distribution
182	74	78	with
182	79	99	standard deviation 1
183	9	14	train
183	15	33	each entity vector
183	34	36	on
183	41	87	entity 's Wikipedia canonical description page
183	113	116	for
183	117	131	400 iterations
190	0	8	Training
190	18	23	takes
190	24	32	20 hours
190	33	35	on
190	38	55	single TitanX GPU
190	56	60	with
190	61	66	12 GB
190	9	11	of
190	70	76	memory
199	0	30	Our local and global ED models
199	35	45	trained on
199	46	78	AIDA - train ( multiple epochs )
199	81	93	validated on
199	94	102	AIDA - A
199	107	116	tested on
199	117	125	AIDA - B
200	3	6	use
200	7	11	Adam
200	12	16	with
200	17	30	learning rate
200	31	33	of
200	34	40	1e - 4
200	41	46	until
200	47	66	validation accuracy
200	67	74	exceeds
200	75	79	90 %
200	93	106	setting it to
200	107	113	1e - 5
206	3	13	regularize
206	19	22	use
206	23	37	early stopping
206	48	52	stop
206	53	61	learning
206	62	64	if
206	69	88	validation accuracy
206	89	106	does not increase
206	107	112	after
206	113	123	500 epochs
207	0	8	Training
207	9	11	on
207	14	24	single GPU
207	25	30	takes
207	33	43	on average
207	46	62	2 ms per mention
207	68	76	16 hours
207	77	80	for
207	81	92	1250 epochs
207	93	97	over
207	98	110	AIDA - train
186	3	6	use
186	7	14	Adagrad
186	15	19	with
186	22	35	learning rate
186	36	38	of
186	39	42	0.3
187	3	9	choose
187	10	24	embedding size
187	25	32	d = 300
187	35	79	pre-trained ( fixed ) Word2 Vec word vectors
187	80	101	8 , ? = 0.6 , ? = 0.1
187	106	117	window size
187	118	120	of
187	121	123	20
187	124	127	for
187	132	142	hyperlinks
18	36	39	use
18	40	53	deep learning
18	63	71	to learn
18	72	86	basic features
18	97	109	combinations
18	110	114	from
18	115	122	scratch
2	5	32	Joint Entity Disambiguation
9	0	28	Entity disambiguation ( ED )
12	0	2	ED
228	3	9	obtain
228	10	35	state of the art accuracy
228	36	38	on
228	39	43	AIDA
232	29	37	analyzed
232	42	50	accuracy
232	51	53	on
232	58	74	AIDA - B dataset
233	0	10	shows that
233	11	21	our method
233	22	30	performs
233	31	35	well
233	36	38	in
233	39	57	these harder cases
