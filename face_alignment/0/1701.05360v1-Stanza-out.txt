title
3D Face Morphable Models " In - the - Wild "
abstract
3D Morphable Models ( 3 DMMs ) are powerful statistical models of 3D facial shape and texture , and among the stateof - the - art methods for reconstructing facial shape from single images .
With the advent of new 3D sensors , many 3 D facial datasets have been collected containing both neutral as well as expressive faces .
However , all datasets are captured under controlled conditions .
Thus , even though powerful 3 D facial shape models can be learnt from such data , it is difficult to build statistical texture models that are sufficient to reconstruct faces captured in unconstrained conditions ( " in - the - wild " ) .
In this paper , we propose the first , to the best of our knowledge , " in - the - wild " 3 DMM by combining a powerful statistical model of facial shape , which describes both identity and expression , with an " in - the -wild " texture model .
We show that the employment of such an " in - thewild " texture model greatly simplifies the fitting procedure , because there is no need to optimize with regards to the illumination parameters .
Furthermore , we propose anew fast algorithm for fitting the 3 DMM in arbitrary images .
Finally , we have captured the first 3 D facial database with relatively unconstrained conditions and report quantitative evaluations with state - of - the - art performance .
Complementary qualitative reconstruction results are demonstrated on standard " in - the - wild " facial databases .
An open source implementation of our technique is released as part of the Menpo Project [ 1 ] .
Introduction
During the past few years , we have witnessed significant improvements in various face analysis tasks such as face detection and 2D facial landmark localization on static images .
This is primarily attributed to the fact that the community has made a considerable effort to collect and annotate facial images captured under unconstrained conditions ( commonly referred to as " in - the -wild " ) and to the discriminative methodologies that can capitalise on the availability of such large amount of data .
Nevertheless , discriminative techniques can not be applied for 3D facial shape estimation " in - the -wild " , due to lack of ground - truth data .
3 D facial shape estimation from single images has attracted the attention of many researchers the past twenty years .
The two main lines of research are ( i ) fitting a 3D Morphable Model ( 3 DMM ) and ( ii ) applying Shape from Shading ( SfS ) techniques .
The 3 DMM fitting proposed in the work of Blanz and Vetter was among the first model - based 3 D facial recovery approaches .
The method requires the construction of a 3 DMM which is a statistical model of facial texture and shape in a space where there are explicit correspondences .
The first 3 DMM was built using 200 faces captured in well - controlled conditions displaying only the neutral expression .
That is the reason why the method was only shown to work on real - world , but not " in - the -wild " , images .
State - of - the - art
SfS techniques capitalise on special multi-linear decompositions that find an approximate spherical harmonic decomposition of the illumination .
Furthermore , in order to benefit from the large availability of " in - the - wild " images , these methods jointly reconstruct large collections of images .
Nevertheless , even thought the results of are quite interesting , given that there is no prior of the facial surface , the methods only recover 2.5 D representations of the faces and particular smooth approximations of the facial normals .
3 D facial shape recovery from a single image under " inthe - wild " conditions is still an open and challenging problem in computer vision mainly due to the fact that :
The general problem of extracting the 3D facial shape from a single image is an ill - posed problem which is notoriously difficult to be solved without the use of any statistical priors for the shape and texture of faces .
That is , without prior knowledge regarding the shape of the object at - hand there are inherent ambiguities present in the problem .
The pixel intensity at a location in an image is the result of a complex combination of the underlying shape of the object , the surface albedo and normal characteristics , camera parameters and the arrangement of scene lighting and other objects in the scene .
Hence , there are potentially infinite solutions to the problem .
Learning statistical priors of the 3D facial shape and texture for " in - the - wild " images is currently very difficult by using modern acquisition devices .
That is , even though there is a considerable improvement in 3D acquisition devices , they still can not operate in arbitrary conditions .
Hence , all the current 3 D facial databases have been captured in controlled conditions .
With the available 3 D facial data , it is feasible to learn a powerful statistical model of the facial shape that generalises well for both identity and expression .
However , it is not possible to construct a statistical model of the facial texture that generalises well for " in - the - wild " images and is , at the same time , in correspondence with the statistical shape model .
That is the reason why current stateof - the - art 3 D face reconstruction methodologies rely solely on fitting a statistical 3 D facial shape prior on a sparse set of landmarks .
In this paper , we make a number of contributions that enable the use of 3 DMMs for " in - the -wild " face reconstruction ( ) .
In particular , our contributions are :
We propose a methodology for learning a statistical texture model from " in - the -wild " facial images , which is in full correspondence with a statistical shape prior that exhibits both identity and expression variations .
Motivated by the success of feature - based ( e.g. , HOG , SIFT ) Active Appearance Models ( AAMs ) we further show how to learn featurebased texture models for 3 DMMs .
We show that the advantage of using the " in - the -wild " feature - based texture model is that the fitting strategy gets simplified since there is not need to optimize with respect to the illumination parameters .
By capitalising on the recent advancements in fitting statistical deformable models , we propose a novel and fast algorithm for fitting " in - the -wild " 3 DMMs .
Furthermore , we make the implementation of our algorithm publicly available , which we believe can be of great benefit to the community , given the lack of robust open - source implementations for fitting 3 DMMs .
Due to lack of ground - truth data , the majority of the 3D face reconstruction papers report only qualitative results .
In this paper , in order to provide quantitative evaluations , we collected anew dataset of 3D facial surfaces , using Kinect Fusion , which has many " in - the -wild " characteristics , even though it is captured indoors .
We release an open source implementation of our technique as part of the Menpo Project .
The remainder of the paper is structured as follows .
In Section 2 we elaborate on the construction of our " inthe -wild " 3 DMM , whilst in Section 3 we outline the proposed optimization for fitting " in - the - wild " images with our model .
Section 4 describes our new dataset , the first of its kind , to provide images with a ground - truth 3 D facial shape that exhibit many " in - the - wild " characteristics .
We outline a series of quantitative and qualitative experiments in Section 5 , and end with conclusions in Section 6 .
Model Training
A 3 DMM consists of three parametric models : the shape , camera and texture models .
Shape Model
Let us denote the 3D mesh ( shape ) of an object with N vertexes as a 3N 1 vector orthonormal basis after keeping the first n s principal components .
This model can be used to generate novel 3 D shape instances using the function S :
where p = [ p 1 , . . . , p ns ]
T are then s shape parameters .
Camera Model
The purpose of the camera model is to map ( project ) the object - centered Cartesian coordinates of a 3D mesh instance s into 2D Cartesian coordinates on an image plane .
In this work , we employ a pinhole camera model , which utilizes a perspective transformation .
However , an orthographic projection model can also be used in the same way .
Perspective projection .
The projection of a 3D point x = [ x , y , z ] T into its 2 D location in the image plane x = [ x , y ]
T involves two steps .
First , the 3D point is rotated and translated using a linear view transformation , under the assumption that the camera is still
T are the 3D rotation and translation components , respectively .
Then , a nonlinear perspective transformation is applied as
where f is the focal length in pixel units ( we assume that the x and y components of the focal length are equal ) and
[ c x , c y ]
T is the principal point that is set to the image center .
Quaternions .
We parametrize the 3D rotation with quaternions .
The quaternion uses four parameters q = [ q 0 , q 1 , q 2 , q 3 ] T in order to express a 3 D rotation as
( 5 ) Note that by enforcing a unit norm constraint on the quaternion vector , i.e. q T q = 1 , the rotation matrix constraints of orthogonality with unit determinant are withheld .
Given the unit norm property , the quaternion can be seen as a three - parameter vector [ q 1 , q 2 , q 3 ] T and a scalar
Most existing works on 3 DMM parametrize the rotation matrix R v using the three Euler angles that define the rotations around the horizontal , vertical and camera axes .
Even thought Euler angles are more naturally interpretable , they have strong disadvantages when employed within an optimization procedure , most notably the solution ambiguity and the gimbal lock effect .
Parametrization based on quaternions overcomes these disadvantages and further ensures computational efficiency , robustness and simpler differentiation .
being the vector of camera parameters with length n c = 7 .
For abbreviation purposes , we represent the camera model of the 3 DMM with the function W : R ns ,nc ?
R 2N as
where S ( p ) is a 3 D mesh instance using Eq. 2 .
" In - the - Wild " Feature - Based Texture Model
The generation of an " in - the -wild " texture model is a key component of the proposed 3 DMM .
To this end , we take advantage of the existing large facial " in - the -wild " databases that are annotated in terms of sparse landmarks .
Assume that fora set of M " in - the - wild " images { I i } M 1 , we have access to the associated camera and shape parameters {p i , c i }.
Let us also define a dense feature extraction function
where C is the number of channels of the feature - based image .
For each image , we first compute its feature - based representation as F i = F (I i ) and then use Eq. 7 to sample it at each vertex location to build back a vectorized texture
Building an ITW texture model will be nonsensical for some regions mainly due to selfocclusions present in the mesh projected in the image space
To alleviate these issues , we cast a ray from the camera to each vertex and test for self - intersections with the triangulation of the mesh in order to learn a per-vertex occlusion mask mi ?
RN for the projected sample .
Let us create the matrix X = [t 1 , . . . , t M ] ?
R CN M by concatenating the M grossly corrupted feature - based texture vectors with missing entries that are represented by the masks mi .
To robustly build a texture model based on this heavily contaminated incomplete data , we need to recover a low - rank matrix L ? R CN M representing the clean facial texture and a sparse matrix E ?
R CN M accounting for gross but sparse non-Gaussian noise such that X = L + E .
To simultaneously recover both Land E from incomplete and grossly corrupted observations , the Principal Component Pursuit with missing values is solved arg min
where * denotes the nuclear norm , 1 is the matrix 1 norm and ? >
0 is a regularizer .
?
represents the set of locations corresponding to the observed entries of X ( i.e. , ( i , j ) ? ?
if mi = m j = 1 ) .
Then , P ? ( X ) is defined as the projection of the matrix X on the observed entries ? , namely P ?
( X ) ij = x ij if ( i , j ) ? ? and P ?
( X ) ij = 0 otherwise .
The unique solution of the convex optimization problem in Eq. 9 is found by employing an Alternating Direction Method of Multipliers - based algorithm .
The final texture model is created by applying PCA on the set of reconstructed feature - based textures acquired from the previous procedure .
This results in {t , Ut } , wher ? t ?
R CN is the mean texture vector and Ut ?
R CN nt is the orthonormal basis after keeping the first n t principal components .
This model can be used to generate novel 3D feature - based texture instances with the function T : R nt ?
R CN as
where ? = [? 1 , . . . , ? nt ]
T are then t texture parameters .
Finally , an iterative procedure is used in order to refine the texture .
That is , we started with the 3D fits provided by using only the 2D landmarks .
Then , a texture model is learned using the above procedure .
The texture model was used with the proposed 3 DMM fitting algorithm on the same data and texture model was refined .
Model Fitting
We propose to fit the 3 DMM on an input image using Gauss - Newton iterative optimization .
To this end , herein , we first formulate the cost function and then present two optimization procedures .
Cost Function
The overall cost function of the proposed 3 DMM formulation consists of a texture - based term , an optional error term based on sparse 2D landmarks and optional regularization terms on the parameters .
Texture reconstruction cost .
The main term of the optimization problem is the one that aims to estimate the shape , texture and camera parameters that minimize the 2 2 norm of the difference between the image feature - based texture that corresponds to the projected 2D locations of the 3D shape instance and the texture instance of the 3 DMM .
Let us denote by F = F ( I ) the feature - based representation with C channels of an input image I using Eq .
8 .
Then , the texture reconstruction cost is expressed as
Note that F ( W ( p , c ) ) ?
R CN denotes the operation of sampling the feature - based input image on the projected 2D locations of the 3D shape instance acquired by the camera model ( Eq. 7 ) .
Regularization .
In order to avoid over - fitting effects , we augment the cost function with two optional regularization terms over the shape and texture parameters .
Let us denote as ? s ?
R nsns and ? t ?
R nt nt the diagonal matrices with the eigenvalues in their main diagonal for the shape and texture models , respectively .
Based on the PCA nature of the shape and texture models , it is assumed that their parameters follow normal prior distributions , i.e. p ? N ( 0 , ? s ) and ? ? N ( 0 , ? t ) .
We formulate the regularization terms as the 2 2 of the parameters ' vectors weighted with the corresponding inverse eigenvalues , i.e.
arg min
where c sand ct are constants that weight the contribution of the regularization terms in the cost function .
2D landmarks cost .
In order to rapidly adapt the camera parameters in the cost of Eq. 11 , we further expand the where s l = [ x 1 , y 1 , . . . , x L , y L ]
T denotes a set of L sparse 2D landmark points ( L N ) defined on the image coordinate system and W l ( p , c ) returns the 2L 1 vector of 2D projected locations of these L sparse landmarks .
Intuitively , this term aims to drive the optimization procedure using the selected sparse landmarks as anchors for which we have the optimal locations s l .
This optional landmarks - based cost is weighted with the constant cl .
Overall cost function .
The overall 3 DMM cost function is formulated as the sum of the terms in Eqs. 11 , 12 , 13 , i.e. arg min
The landmarks term as well as the regularization terms are optional and aim to facilitate the optimization procedure in order to converge faster and to a better minimum .
Note that thanks to the proposed " in - the - wild " feature - based texture model , the cost function does not include any parametric illumination model similar to the ones in the relative literature , which greatly simplifies the optimization .
Gauss - Newton Optimization
Inspired by the extensive literature in Lucas - Kanade 2D image alignment , we formulate a Gauss - Newton optimization framework .
Specifically , given that the camera projection model is applied on the image part of Eq. 14 , the proposed optimization has a " forward " nature .
Parameters update .
The shape , texture and camera parameters are updated in an additive manner , i.e. p ? p + ? p , ? ? ? + ?? , c ? c + ?c where ? p , ?? and ?c are their increments estimated at each fitting iteration .
Note that in the case of the quaternion used to parametrize the 3D rotation matrix , the update is performed as the multiplication q ?(? q ) q = ?q 0 ? q 1:3 q 0 q 1:3 = = ?q 0 q 0 ? ?q T 1:3 q 1:3 ?q 0 q 1:3 + q 0 ?q 1:3 + ? q 1:3 q 1:3
However , we will still denote it as an addition for simplicity .
Finally , we found that it is beneficial to keep the focal length constant inmost cases , due to its ambiguity with t z .
Linearization .
By introducing the additive incremental updates on the parameters of Eq. 14 , the cost function is where J F , p = ? F ? W ?p p=p and J F , c = ? F ? W ?c
c=c are the image Jacobians with respect to the shape and camera parameters , respectively .
Note that most dense featureextraction functions F ( ) are non-differentiable , thus we simply compute the gradient of the multi -channel feature image ?
F . Similarly , the linearization on the sparse landmarks projection term gives
and J W l , c = ? W l ?c
c=c are the camera Jacobians .
Please refer to the supplementary material for more details on the computation of these derivatives .
Simultaneous
Herein , we aim to simultaneously solve for all parameters ' increments .
By substituting Eqs .
and e F = F ( W ( p , c ) ) ? T (? )
are the residual terms .
The computational complexity of the Simultaneous algorithm per iteration is dominated by the texture reconstruction term as O ( ( n s + n c + n t )
3 + CN ( n s + n c + n t ) 2 ) , which in practice is too slow .
Project - Out
We propose to use a Project - Out optimization approach that is much faster than the Simultaneous .
The main idea is to optimize on the orthogonal complement of the texture subspace which will eliminate the need to solve for the texture parameters increment at each iteration .
By substituting Eqs. 18 and 19 into Eq. 17 and removing the incremental update on the texture parameters as well as the texture parameters regularization term , we end up with the problem
T is the orthogonal complement of the texture subspace that functions as the " project - out " operator with E denoting the CN CN unitary matrix .
Note that in order to derive Eq. 26 , we use the properties PT = P and PT P = P .
By differentiating Eq. 26 and equalizing to zero , we get the solution
where
are the Hessian matrices and
are the residual terms .
The texture parameters can be estimated at the end of the iterative procedure using Eq. 25 .
Note that the most expensive operation is J T F , p P. However , if we first do J T F , p Ut and then multiply this result with UT t , the total cost becomes O ( CN n tn s ) .
The same stands for J T F , c P .
Consequently , the cost per iteration is O ( ( n s + n c )
3 + CN n t ( n s + n c ) + CN ( n s + n c ) 2 ) which is much faster than the Simultaneous algorithm .
Residual masking .
In practice , we apply a mask on the texture reconstruction residual of the Gauss - Newton optimization , in order to speed - up the 3 DMM fitting .
This mask is constructed by first acquiring the set of visible vertexes using z- buffering and then randomly selecting K of them .
By keeping the number of vertexes small ( K ? 5000 N ) , we manage to greatly speed - up the fitting process without any accuracy penalty .
KF - ITW
Dataset
For the evaluation of the 3 DMM , we have constructed KF - ITW , the first dataset of 3D faces captured under relatively unconstrained conditions .
The dataset consists of 17 different subjects recorded under various illumination conditions performing a range of expressions ( neutral , happy , surprise ) .
We employed the KinectFusion framework to acquire a 3D representation of the subjects with a Kinect v 1 sensor .
The fused mesh for each subject serves as a 3D face ground - truth in which we can evaluate our algorithm and compare it to other methods .
A voxel grid of size 608 3 was utilized to get the detailed 3 D scans of the faces .
In order to accurately reconstruct the entire surface of the faces , a circular motion scanning pattern was carried out .
Each subject was instructed to stay still in a fixed pose during the entire scanning process .
The frame rate for every subject was constant to 8 frames per second .
After getting the 3D scans from the KinectFusion framework we fit our shape model in a non-rigid manner to get a clear mesh with a distinct number of vertexes for the evaluation process .
Finally , each mesh was manually annotated with the iBUG 49 sparse landmark set .
Experiments
To train our model , which we label as ITW , we use a variant of the Basel Face Model ( BFM ) that we trained to contain both identities drawn from the original BFM model along with expressions provided by .
We trained the " in - the -wild " texture model on the images of iBUG , LFPW & AFW datasets as described in Sec. 2.3 using the 3D shape fits provided by .
Additionally , we elect to use the project - out formulation for the throughout our experiments due its superior run-time performance and equivalent fitting performance to the simultaneous one .
reports additional measures .
3D Shape Recovery
Herein , we evaluate our " in - the -wild " 3 DMM ( ITW ) in terms of 3D shape estimation accuracy against two popular state - of - the - art alternative 3 DMM formulations .
The first one is a classic 3 DMM with the original Basel laboratory texture model and full lighting equation which we term Classic .
The second is the texture - less linear model proposed in which we refer to as Linear .
For Linear code we use the Surrey Model with related blendshapes along with the implementation given in .
We use the ground - truth annotations provided in the KF - ITW dataset to initialize and fit all three techniques to the " in - the -wild " style images in the dataset .
The mean mesh of each model under testis landmarked with the same 49 point markup used in the dataset , and is registered against the ground truth mesh by performing a Procrustes alignment using the sparse annotations followed by Non-Rigid Iterative Closest Point ( N - ICP ) to iteratively deform the two surfaces until they are brought into correspondence .
This provides a per-model ' ground - truth ' for the 3D shape recovery problem for each image under test .
Our error metric is the per-vertex dense error between the recovered shape and the model - specific corresponded ground - truth fit , normalized by the inter-ocular distance for the test mesh .
shows the cumulative error distribution for this experiment for the three models under test .
reports the corresponding Area
Under the Curve ( AUC ) and failure rates .
The Classic model struggles to fit to the " in - the -wild " conditions present in the test set , and performs the worst .
The texture - free Linear model does better , but the ITW model is most able to recover the facial shapes due to its ideal feature basis for the " in - the -wild " conditions .
demonstrates qualitative results on a wide range of fits of " in - the - wild " images drawn from the Helen and 300 W datasets that qualitatively highlight the effectiveness of the proposed technique .
We note that in a wide variety of expression , identity , lighting and occlusion conditions our model is able to robustly reconstruct a realistic 3 D facial shape that stands up to scrutiny .
Quantitative Normal Recovery
As a second evaluation , we use our technique to find per-pixel normals and compare against two well established Shape - from - Shading ( SfS ) techniques : PS - NL and IMM .
For experimental evaluation we employ images of 100 subjects from the Photoface database .
As a set of four illumination conditions are provided for each subject then we can generate ground - truth facial surface normals using calibrated 4 - source Photometric Stereo .
In we show the cumulative error distribution in terms of the mean angular error .
ITW slightly outperforms IMM even though both IMM and PS - NL use all four available images of each subject .
Conclusion
We have presented a novel formulation of 3 DMMs reimagined for use in " in - the -wild " conditions .
We capitalise on the annotated " in - the - wild " facial databases to propose a methodology for learning an " in - the -wild " feature - based texture model suitable for 3 DMM fitting without having to optimise for illumination parameters .
Furthermore , we propose a novel optimisation procedure for 3 DMM fitting .
We show that we are able to recover shapes with more detail than is possible using purely landmark - driven approaches .
Our newly introduced " in - the -wild " KinectFusion dataset allows for the first time a quantitative evaluation of 3D fa-cial reconstruction techniques in the wild , and on these evaluations we demonstrate that our in the wild formulation is state of the art , outperforming classical 3 DMM approaches by a considerable margin .
