287	102	104	on
287	105	113	300 - VW
290	4	22	Semantic alignment
290	27	47	consistently improve
290	52	63	performance
290	64	66	on
290	67	82	all subset sets
291	0	4	GHCU
291	8	22	more effective
291	23	25	on
291	30	63	challenge data set ( Category 3 )
291	66	82	8.15 % vs 9.91 %
201	0	10	To perform
201	11	28	data augmentation
201	34	49	randomly sample
201	54	71	angle of rotation
201	80	98	bounding box scale
201	99	103	from
201	104	125	Gaussian distribution
202	3	6	use
202	9	47	four - stage stacked hourglass network
202	48	50	as
202	55	63	backbone
202	73	83	trained by
202	88	105	optimizer RMSprop
207	0	4	When
207	5	13	training
207	18	41	roughly converged model
207	42	46	with
207	47	64	human annotations
207	71	92	initial learning rate
207	96	105	2.5 10 ?4
207	115	122	decayed
207	123	125	to
207	126	136	2.5 10 ? 6
207	137	142	after
207	143	153	120 epochs
208	14	18	with
208	19	37	Semantic Alignment
208	109	130	initial learning rate
208	134	144	2.5 10 ? 6
208	152	162	divided by
208	163	174	5 , 2 and 2
208	175	177	at
208	178	198	epoch 30 , 60 and 90
211	3	6	set
211	7	17	batch size
211	18	20	to
211	21	23	10
211	24	27	for
211	28	44	network training
213	8	18	our models
213	23	30	trained
213	31	35	with
213	36	43	PyTorch
213	51	53	on
213	54	68	2 Titan X GPUs
30	19	26	propose
30	29	60	novel Semantic Alignment method
30	67	74	reduces
30	79	116	' semantic ambiguity ' intrinsi-cally
33	27	46	probabilistic model
33	72	78	search
33	83	106	' real ' ground - truth
33	111	116	train
33	121	147	landmark detection network
33	148	150	in
33	154	172	end - to - end way
37	71	110	global heatmap correction unit ( GHCU )
37	117	126	maintains
37	131	159	global face shape constraint
37	164	172	recovers
37	177	210	unconfidently predicted landmarks
37	211	220	caused by
37	221	240	challenging factors
37	241	248	such as
37	249	259	occlusions
37	264	278	low resolution
37	279	281	of
37	282	288	images
32	3	8	model
32	13	36	' real ' ground - truth
32	37	39	as
32	42	57	latent variable
32	58	60	to
32	61	69	optimize
32	80	113	optimized ' real ' ground - truth
32	119	129	supervises
32	134	169	landmark detection network training
34	8	27	probabilistic model
34	34	45	prior model
34	52	61	constrain
34	66	81	latent variable
34	82	96	to be close to
34	101	113	observations
34	114	116	of
34	121	142	' real ' ground truth
35	4	20	likelihood model
35	27	33	reduce
35	38	65	Pearson Chi-square distance
35	66	73	between
35	78	118	expected and the predicted distributions
35	119	121	of
35	122	145	' real ' ground - truth
36	4	11	heatmap
36	12	24	generated by
36	29	51	hourglass architecture
36	52	62	represents
36	67	77	confidence
36	78	80	of
36	81	91	each pixel
36	101	124	confidence distribution
36	128	141	used to model
36	146	168	predicted distribution
36	169	171	of
36	172	182	likelihood
2	72	97	Facial Landmark Detection
215	0	5	300 W
220	11	19	see that
220	20	23	HGs
220	24	28	with
220	29	64	our Semantic Alignment ( HGs + SA )
220	65	83	greatly outperform
220	84	106	hourglass ( HGs ) only
220	109	125	4.37 % vs 5.04 %
220	126	137	in terms of
220	138	141	NME
220	142	144	on
220	145	153	Full set
220	156	163	showing
220	168	187	great effectiveness
220	188	190	of
220	191	220	our Semantic Alignment ( SA )
221	3	9	adding
221	10	14	GHCU
221	24	27	see
221	33	48	HGs + SA + GHCU
221	49	69	slightly outperforms
221	74	82	HGs + SA
223	20	29	normalize
223	34	55	in - plane - rotation
223	56	67	by training
223	70	91	preprocessing network
223	155	162	achieve
223	163	191	state of the art performance
223	192	194	on
223	195	221	Challenge set and Full set
223	224	241	6.38 % and 4.02 %
224	16	18	on
224	19	32	Challenge set
224	38	62	significantly outperform
224	67	90	state of the art method
224	93	99	6.38 %
224	102	123	HGs + SA +GHCU + Norm
224	126	128	vs
224	129	135	6.98 %
224	138	141	LAB
225	0	4	AFLW
230	21	29	HGs + SA
230	30	41	outperforms
231	0	3	HGs
231	6	22	1.62 % vs 1.95 %
233	11	24	observed that
233	25	40	HGs + SA + GHCU
233	41	46	works
233	47	53	better
233	54	58	than
233	59	67	HGs + SA
234	0	8	300 - VW
238	11	14	see
238	20	28	HGs + SA
238	29	48	greatly outperforms
238	49	52	HGs
239	14	27	compared with
239	28	36	HGs + SA
239	39	54	HGs + SA + GHCU
239	55	61	reduce
239	66	85	error rate ( RMSE )
239	86	88	by
239	89	93	18 %
239	94	96	on
239	97	116	Category 3 test set
