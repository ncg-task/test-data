title
Dense Face Alignment
abstract
Face alignment is a classic problem in the computer vision field .
Previous works mostly focus on sparse alignment with a limited number of facial landmark points , i.e. , facial landmark detection .
In this paper , for the first time , we aim at providing a very dense 3D alignment for largepose face images .
To achieve this , we train a CNN to estimate the 3D face shape , which not only aligns limited facial landmarks but also fits face contours and SIFT feature points .
Moreover , we also address the bottleneck of training CNN with multiple datasets , due to different landmark markups on different datasets , such as 5 , 34 , 68 .
Experimental results show our method not only provides highquality , dense 3 D face fitting but also outperforms the stateof - the - art facial landmark detection methods on the challenging datasets .
Our model can run at real time during testing and it 's available at
Introduction
Face alignment is a long - standing problem in the computer vision field , which is the process of aligning facial components , e.g. , eye , nose , mouth , and contour .
An accurate face alignment is an essential prerequisite for many face related tasks , such as face recognition , 3 D face reconstruction and face animation .
There are fruitful previous works on face alignment , which can be categorized as generative methods such as the early Active Shape Model and Active Appearance Model ( AAM ) based approaches , and discriminative methods such as regression - based approaches .
Most previous methods estimate a sparse set of landmarks , e.g. , 68 landmarks .
As this field is being developed , we believe that Dense Face Alignment ( DeFA ) becomes highly desired .
Here , DeFA denotes that it 's doable to map any face - region pixel to the pixel in other face images , which has the same anatomical position inhuman faces .
For example , given two face images from the same .
A pair of images with their dense 3D shapes obtained by imposing landmark fitting constraint , contour fitting constraint and sift pair constraint .
individual but with different poses , lightings or expressions , a perfect DeFA can even predict the mole ( i.e. darker pigment ) on two faces as the same position .
Moreover , DeFA should offer dense correspondence not only between two face images , but also between the face image and the canonical 3 D face model .
This level of detailed geometry interpretation of a face image is invaluable to many conventional facial analysis problems mentioned above .
Since this interpretation has gone beyond the sparse set of landmarks , fitting a dense 3 D face model to the face image is a reasonable way to achieve DeFA .
In this work , we choose to develop the idea of fitting a dense 3 D face model to an image , where the model with thousands of vertexes makes it possible for face alignment to go very " dense " .
3 D face model fitting is well studied in the seminal work of 3D Morphorbal Model ( 3 DMM ) .
We see a recent surge when it is applied to problems such as large - pose face alignment , 3D reconstruction , and face recognition , especially using the convolutional neural network ( CNN ) architecture .
However , most prior works on 3D - model - fitting - based face alignment only utilize the sparse landmarks as supervision .
There are two main challenges to be addressed in 3D face model fitting , in order to enable high - quality DeFA .
First of all , to the best of our knowledge , no public face dataset has dense face shape labeling .
All of the in - the - wild face alignment datasets have no more than 68 landmarks in the labeling .
Apparently , to provide a high - quality alignment for face - region pixels , we need information more than just the landmark labeling .
Hence , the first challenge is to seek valuable information for additional supervision and in - tegrate them in the learning framework .
Secondly , similar to many other data - driven problems and solutions , it is preferred that multiple datasets can be involved for solving face alignment task since a single dataset has limited types of variations .
However , many face alignment methods can not leverage multiple datasets , because each dataset either is labeled differently .
For instance , AFLW dataset contains a significant variation of poses , but has a few number of visible landmarks .
In contrast , 300W dataset contains a large number of faces with 68 visible landmarks , but all faces are in a near - frontal view .
Therefore , the second challenge is to allow the proposed method to leverage multiple face datasets .
With the objective of addressing both challenges , we learn a CNN to fit a 3 D face model to the face image .
While the proposed method works for any face image , we mainly pay attention to faces with large poses .
Large - pose face alignment is a relatively new topic , and the performances in still have room to improve .
To tackle first challenge of limited landmark labeling , we propose to employ additional constraints .
We include contour constraint where the contour of the predicted shape should match the detected 2 D face boundary , and SIFT constraint where the SIFT key points detected on two face images of the same individual should map to the same vertexes on the 3D face model .
Both constraints are integrated into the CNN training as additional loss function terms , where the end - to - end training results in an enhanced CNN for 3 D face model fitting .
For the second challenge of leveraging multiple datasets , the 3D face model fitting approach has the inherent advantage in handling multiple training databases .
Regardless of the landmark labeling number in a particular dataset , we can always define the corresponding 3 D vertexes to guide the training .
Generally , our main contributions can be summarized as : 1 . We identify and define anew problem of dense face alignment , which seeks alignment of face - region pixels beyond the sparse set of landmarks .
2 .
To achieve dense face alignment , we develop a novel 3 D face model fitting algorithm that adopts multiple constraints and leverages multiple datasets .
3 .
Our dense face alignment algorithm outperforms the SOTA on challenging large - pose face alignment , and achieves competitive results on near - frontal face alignment .
The model runs at real time .
Related Work
We review papers in three relevant areas : 3 D face alignment from a single image , using multiple constraints in face alignment , and using multiple datasets for face alignment .
3D model fitting in face alignment
Recently , there are increasingly attentions in conducting face alignment by fitting the 3D face model to the single 2D image .
In , Blanz and Vetter proposed the 3 DMM to represent the shape and texture of a range of individuals .
The analysis - by - synthesis based methods are utilized to fit the 3 DMM to the face image .
Ina set of cascade CNN regressors with the extracted 3D features is utilized to estimate the parameters of 3 DMM and the projection matrix directly .
Liu et al. proposed to utilize two sets of regressors , for estimating update of 2D landmarks and the other set estimate update of dense 3 D shape by using the 2D landmarks update .
They apply these two sets of regressors alternatively .
Compared to prior work , our method imposes additional constraints , which is the key to dense face alignment .
Multiple constraints in face alignment
Other than landmarks , there are other features that are useful to describe the shape of a face , such as contours , pose and face attributes .
Unlike landmarks , those features are often not labeled in the datasets .
Hence , the most crucial step of leveraging those features is to find the correspondence between the features and the 3D shape .
In , multiple features constraints in the cost function is utilized to estimate the 3D shape and texture of a 3 D face .
2 D edge is detected by Canny detector , and the corresponding 3D edges ' vertices are matched by Iterative Closest Point ( ICP ) to use this information .
Furthermore , provides statistical analysis about the 2D face contours and the 3D face shape under different poses .
There is a few work using constraints as separate side tasks to facilitate face alignment .
In , they set a pose classification task , predicting faces as left , right profile or frontal , in order to assist face alignment .
Even with such a rough pose estimation , this information boosts the alignment accuracy .
Zhang et al. jointly estimates 2 D landmarks update with the auxiliary attributes ( e.g. , gender , expression ) in order to improve alignment accuracy .
The " mirrorability " constraint is used in to force the estimated 2D landmarks update be consistent between the image and its mirror image .
In contrast , we integrate a set of constraints in an end - to - end trainable CNN to perform 3 D face alignment .
Multiple datasets in face alignment Despite the huge advantages ( e.g. , avoiding dataset bias ) , there are only a few face alignment works utilizing multiple datasets , owing to the difficulty of leveraging different types of face landmark labeling .
Zhu et al.
propose a transductive supervised descent method to transfer face annotation from a source dataset to a target dataset , and use both datasets for training .
ensembles a non-parametric appearance model , shape model and graph matching to estimate the superset of the landmarks .
Even though achieving good results , it suffers from high computation cost .
Zhang et al. propose a deep regression network for predicting the superset of landmarks .
For each training sample , the sparse shape regression is adopted to generate the different types of landmark annotations .
In general , most of the mentioned prior work learn to map landmarks between two datasets , while our method can readily handle an arbitrary number of datasets since the dense 3 D face model can bridge the discrepancy of landmark definitions in various datasets .
Dense Face Alignment
In this section , we explain the details of the proposed dense face alignment method .
We train a CNN for fitting the dense 3 D face shape to a single input face image .
We utilize the dense 3D shape representation to impose multiple constraints , e.g. , landmark fitting constraint , contour fitting constraint and SIFT pairing constraint , to train such CNN .
3D
Face Representation
We represent the dense 3D shape of the face as , S , which contains the 3D locations of Q vertices ,
To compute S fora face , we follow the 3 DMM to represent it by a set of 3D shape bases ,
where the face shape S is the summation of the mean shapeS and the weighted PCA shape bases Sid and S exp with corresponding weights of p id , p exp .
In our work , we use 199 shape bases Si id , i = { 1 , ... , 199 } for representing identification variances such as tall / short , light / heavy , and male / female , and 29 shape bases Si exp , i = { 1 , ... , 29 } for representing expression variances such as mouth - opening , smile , kiss and etc .
Each basis has Q = 53 , 215 vertices , which are corresponding to vertices overall the other bases .
The mean shapeS and the identification bases Sid are from Basel Face Model , and the expression bases S exp are from FaceWarehouse .
A subset of N vertices of the dense 3 D face U corresponds to the location of 2D landmarks on the image ,
By considering weak perspective projection , we can estimate the dense shape of a 2 D face based on the 3D face shape .
The projection matrix has 6 degrees of freedom and can model changes w.r.t. scale , rotation angles ( pitch ? , yaw ? , roll ? ) , and translations ( t x , t y ) .
The transformed dense face shape A ?
R 3Q can be represented as ,
where A can be orthographically projected onto 2 D plane to achieve U. Hence , z - coordinate translation ( m 12 ) is out of our interest and assigned to be 0 .
The orthographic projection can be denoted as matrix Pr = 1 0 0 0 1 0 .
Given the properties of projection matrix , the normalized third row of the projection matrix can be represented as the outer product of normalized first two rows , Therefore , the dense shape of an arbitrary 2 D face can be determined by the first two rows of the projection parameters m = [ m 1 , , m 8 ] ?
R 8 and the shape basis
The learning of the dense 3D shape is turned into the learning of m and p , which is much more manageable in term of the dimensionality .
CNN
Architecture
Due to the success of deep learning in computer vision , we employ a convolutional neural network ( CNN ) to learn the nonlinear mapping function f ( ? ) from the input image Ito the corresponding projection parameters m and shape parameters p.
The estimated parameters can then be utilized to construct the dense 3 D face shape .
Our CNN network has two branches , one for predicting m and another for p , shown in .
Two branches share the first three convolutional blocks .
After the third block , we use two separate convolutional blocks to extract taskspecific features , and two fully connected layers to transfer the features to the final output .
Each convolutional block is a stack of two convolutional layers and one max pooling layer , and each conv / fc layer is followed by one batch normalization layer and one leaky ReLU layer .
In order to improve the CNN learning , we employ a loss function including multiple constraints :
Parameter Constraint ( PC ) J pr minimizes the difference between the estimated parameters and the ground truth parameters ; Landmark Fitting Constraint ( LFC )
J lm reduces the alignment error of 2D landmarks ; Contour Fitting Constraint ( CFC ) J c enforces the match between the contour of the estimated 3D shape and the contour pixels of the input image ; and SIFT Pairing Constraint ( SPC ) J s encourages that the SIFT feature point pairs of two face images to correspond to the same 3D vertices .
We define the overall loss function as ,
where the parameter constraint ( PC ) loss is defined as ,
Landmark Fitting Constraint ( LFC ) aims to minimize the difference between the estimated 2D landmarks and the ground truth 2D landmark labeling U lm ?
R 2 N .
Given 2 D face images with a particular landmark labeling , we first manually mark the indexes of the 3D face vertices that are anatomically corresponding to these landmarks .
The collection of these indexes is denoted as i lm .
After the shape A is computed from Eqn. 4 with the estimatedm andp , the 3D landmarks can be extracted from A by A ( : , i lm ) .
With projection of A ( : , i lm ) to 2 D plain , the LFC loss is defined as ,
( a ) ( b ) ( c ) .
The CFC fitting process .
Ac is computed from estimated 3 D face shape and Uc is computed from the off - the - shelf edge detector .
Contour correspondence is obtained via Closest Pair Algorithm , and loss Jc is calculated based on Eqn.
10
where the subscript F represents the Frobenius Norm , and L is the number of pre-defined landmarks .
Contour Fitting Constraint ( CFC )
Contour Fitting Constraint ( CFC ) aims to minimize the error between the projected outer contour ( i.e. , silhouette ) of the dense 3D shape and the corresponding contour pixels in the input face image .
The outer contour can be viewed as the boundary between the background and the 3D face while rendering 3 D space onto a 2D plane .
On databases such as AFLW where there is alack of labeled landmarks on the silhouette due to self - occlusion , this constraint can be extremely helpful .
To utilize this contour fitting constraint , we need to follow these three steps :
1 ) Detect the true contour in the 2 D face image ; 2 ) Describe the contour vertices on the estimated 3D shape A ; and 3 )
Determine the correspondence between true contour and the estimated one , and backpropagate the fitting error .
First of all , we adopt an off - the - shelf edge detector , HED , to detect the contour on the face image , U c ?
R 2 L .
The HED has a high accuracy at detecting significant edges such as face contour in our case .
Additionally , in certain datasets , such as 300 W and AFLW - LPFA , additional landmark labelings on the contours are available .
Thus we can further refine the detected edges by only retaining edges that are within a narrow band determined by those contour landmarks , shown ina .
This preprocessing step is done offline before the training starts .
In the second step , the contour on the estimated 3D shape A can be described as the set of boundary vertices A ( : , i c ) ?
R 3 L .
A is computed from the estimatedm and p parameters .
By utilizing the Delaunay triangulation to represent shape A , one edge of a triangle is defined as the boundary if the adjacent faces have a sign change in the zvalues of the surface normals .
This sign change indicates a change of visibility so that the edge can be considered as a boundary .
The vertices associated with this edge are defined as boundary vertices , and their collection is denoted as i c .
This process is shown inb .
In the third step , the point - to - point correspondences between U c and A ( : , i c ) are needed in order to evaluate the constraint .
Given that we normally detect partial contour pixels on 2D images while the contour of 3D shape is typically complete , we match the contour pixel on the 2D images with closest point on 3D shape contour , and then calculate the minimun distance .
The sum of all minimum distances is the error of CFC , as shown in the Eqn. 10 .
To make CFC loss differentiable , we rewrite Eqn. 10 to compute the vertex index of the closest contour projection point , i.e. , k 0 = arg min k? ic PrA ( : , k) ? U c (: , j) 2 . Once k 0 is determined , the CFC loss will be differentiable , similar to Eqn .
9 .
SIFT Pairing Constraint ( SPC )
SIFT Pairing Constraint ( SPC ) regularizes the predictions of dense shape to be consistent on the significant facial points other than pre-defined landmarks , such as edges , wrinkles , and moles .
The Scale - invariant feature transform ( SIFT ) descriptor is a classic local representation that is invariant to image scaling , noise , and illumination .
It is widely used in many regression - based face alignment methods to extract the local information .
In our work , the SIFT descriptors are used to detect and represent the significant points within the face pair .
The face pair can either come from the same people with different poses and expressions , or the same image with different augmentation , e.g. , cropping , rotation and 3D augmentation , shown in .
The more face pairs we have , the stronger this constraint is .
Given a pair of faces i and j , we first detect and match SIFT points on two face images .
The matched SIFT points are denoted as U i sand U j s ?
R 2 Lij .
With a perfect dense face alignment , the matched SIFT points would overlay with exactly the same vertex in the estimated 3 D face shapes , denoted as A i and A j .
In practices , to verify how likely this ideal world is true and leverage it as a constraint , we first find the 3D vertices ii s whose projections overlay with the 2D SIFT points , U i s .
Similarly , we find j j s based on U j s .
Now we define the SPC loss function as
where A i is computed using {m i , pi }.
As shown in , we map SIFT points from one face to the other and compute their distances w.r.t. the matched SIFT points on the other face .
With the mapping from both images , we have two terms in the loss function of Eqn. 12 .
Experimental Results
Datasets
We evaluate our proposed method on four benchmark datasets : AFLW - LFPA , AFLW2000 - 3D , 300W and IJBA .
All datasets used in our training and testing phases are listed in Tab .
1 . AFLW - LFPA : AFLW contains around 25 , 000 face images with yaw angles between 90 , and each image is labeled with up to 21 visible landmarks .
In , a subset of AFLW with a balanced distribution of the yaw angle is introduced as AFLW - LFPA .
It consists of 3 , 901 training images and 1 , 299 testing images .
Each image is labeled with 13 additional landmarks .
AFLW2000 - 3D : Prepared by , this dataset contains 2 , 000 images with yaw angles between 90 of the AFLW dataset .
Each image is labeled with 68 landmarks .
Both this dataset and AFLW - LFPA are widely used for evaluating large - pose face alignment .
IJBA : IARPA Janus Benchmark A ( IJB - A ) is an inthe-wild dataset containing 500 subjects and 25 , 795 images with three landmark , two landmarks at eye centers and one on the nose .
While this dataset is mainly used for face recognition , the large dataset size and the challenging variations ( e.g. , 90 yaw and images resolution ) make it suitable for evaluating face alignment as well .
300W : 300W integrates multiple databases with standard 68 landmark labels , including AFW , LFPW , HELEN , and IBUG .
This is the widely used database for evaluating near - frontal face alignment .
COFW : This dataset includes near - frontal face images with occlusion .
We use this dataset in training to make the model more robust to occlusion .
Caltech10k : It contains four labeled landmarks : two on eye centers , one on the top of the nose and one mouth center .
We do not use the mouth center landmark since there is no corresponding vertex on the 3D shape existing for it .
LFW : Despite having no landmark labels , LFW can be used to evaluate how dense face alignment method performs via the corresponding SIFT points between two images of the same individual .
Experimental setup
Training sets and procedures :
While utilizing multiple datasets is beneficial for learning an effective model , it also poses challenges to the training procedure .
To make the training more manageable , we train our DeFA model in three stages , with the intention to gradually increase the datasets and employed constraints .
At stage 1 , we use 300W - LP to train our DeFA network with parameter constraint ( PL ) .
At stage 2 , we additionally include samples from the Caltech10K , and COFW to continue the training of our network with the additional landmark fitting constraint ( LFC ) .
At stage 3 , we fine - tune the model with SPC and CFC constraints .
For large - pose face alignment , we fine - tune the model with AFLW - LFPA training set .
For near - frontal face alignment , we fine - tune the model with 300 W training set .
All samples at the third stage are augmented 20 times with up to 20 random in - plain rotation and 15 % random noise on the center , width , and length of the initial bounding box .
Tab. 2 shows the datasets and .
To train the network , we use 20 , 10 , and 10 epochs for stage 1 to 3 .
We set the initial global learning rate as 1 e ? 3 , and reduce the learning rate by a factor of 10 when the training error approaches a plateau .
The minibatch size is 32 , weight decay is 0.005 , and the leak factor for Leaky ReLU is 0.01 .
In stage 2 , the regularization weights ?
pr for PC is 1 and ?
lm for LFC is 5 ; In stage 3 , the regularization weights ? lm , ? s , ?
c for LFC , SPC and CFC are set as 5 , 1 and 1 , respectively .
Evaluation metrics :
For performance evaluation and comparison , we use two metrics for normalizing the MSE .
We follow the normalization method in for large - pose faces , which normalizes the MSE by using the bounding box size .
We term this metric as " NME - lp " .
For the nearfrontal view datasets such as 300 W , we use the inter-ocular distance for normalizing the MSE , termed as " NME - nf " .
Experiments on Large - pose Datasets
To evaluate the algorithm on large - pose datasets , we use the AFLW - LFPA , AFLW2000 - 3D , and IJB - A datasets .
The results are presented in Tab. 3 , where the performance of the baseline methods is either reported from the published papers or by running the publicly available source code .
For AFLW - LFPA , our method outperforms the best methods with a large margin of 17.8 % improvement .
For AFLW2000 - 3D , our method also shows a large improvement .
Specifically , for images with yaw angle in [ 60 , 90 ] , our method improves the performance by 28 % ( from 7.93 to 5.68 ) .
For the IJB - A dataset , even though we are able to only compare the accuracy for the three labeled landmarks , our method still reaches a higher accuracy .
Note that the best performing baselines , 3DDFA and PAWF , share the similar overall approach in estimating m and p , and also aim for large - pose face alignment .
The consistently superior performance of our DeFA indicates that we have advanced the state of the art in large - pose face alignment .
Experiments on Near-frontal Datasets
Even though the proposed method can handle largepose alignment , to show its performance on the near- frontal datasets , we evaluate our method on the 300W dataset .
The result of the state - of - the - art method on the both common and challenging sets are shown in Tab .
4 . To find the corresponding landmarks on the cheek , we apply the landmark marching algorithm to move contour landmarks from self - occluded location to the silhouette .
Our method is the second best method on the challenging set .
In general , the performance of our method is comparable to other methods that are designed for near - frontal datasets , especially under the following consideration .
That is , most prior face alignment methods do not employ shape constraints such as 3 DMM , which could bean advantage for near - frontal face alignment , but might be a disadvantage for large - pose face alignment .
The only exception in Tab. 4 in 3DDFA , which attempted to overcome the shape constraint by using the additional SDM - based finetuning .
It is a strong testimony of our model in that DeFA , without further finetuning , outperforms both 3DDFA and its fine tuned version with SDM .
Ablation Study
To analyze the effectiveness of the DeFA method , we design two studies to compare the influence of each part in the DeFA and the improvement by adding each dataset .
Tab. 5 shows the consistent improvement achieved by utilizing more datasets in different stages and constraints according to Tab.
2 on both testing datasets .
It shows the advantage and the ability of our method in leveraging more datasets .
The accuracy of our method on the AFLW2000 - 3D consistently improves by adding more datasets .
For the AFLW - PIFA dataset , our method achieves 9.5 % and 20 % relative improvement by utilizing the datasets in the stage 2 and stage 3 over the first stage , respectively .
If including the datasets from both the second and third stages , we can have 26 % relative improvement and achieve NME of 3.86 % .
Comparing the second and third rows in Tab .
5 shows that the effectiveness of CFC and SPC is more than LFC .
This is due to the utilization of more facial matching in the CFC and SPC .
The second study shows the performance improvement achieved by using the proposed constraints .
We train models with different types of active constraints and test them on the AFLW - PIFA test set .
Due to the time constraint , for this experiment , we did not apply 20 times augmentation of the third stage 's dataset .
We show the results in the left of .
Comparing LFC + SPC and LFC + CFC performances shows that the CFC is more helpful than the SPC .
The reason is that CFC is more helpful in correcting the pose of the face and leads to more landmark error reduction .
Using all constraints achieves the best performance .
Finally , to evaluate the influence of using the SIFT pairing constraint ( SPC ) , we use all of the three stages datasets to train our method .
We select 5 , 000 pairs of images from the IJB - A dataset and compute the NME - lp of all matched SIFT points according to Eqn. 12 .
The right plot in illustrates the CED diagrams of NME - lp , for the trained models with and without the SIFT pairing constraint .
This result shows that for the images with NME - lp between 5 % and 15 % the SPC is helpful .
Part of the reason DeFA works well is that it receives .
The estimated dense 3D shape and their landmarks with visibility labels for different datasets .
From top to bottom , the results on AFLW - LPFA , IJB - A and 300W datasets are shown in two rows each .
The green landmark are visible and the red landmarks show the estimated locations for invisible landmarks .
Our model can fit to diverse poses , resolutions , and expressions .
" dense " supervision .
To show that , we take all matched SIFT points in the 300W - LP dataset , find their corresponding vertices , and plot the log of the number of SIFT points on each of the 3D face vertex .
As shown in , SPC utilizes SIFT points to cover the whole 3D shape and the points in the highly textured areas are substantially used .
We can expect that these SIFT constraints will act like anchors to guild the learning of the model fitting process .
Conclusion
We propose a large - pose face alignment method which estimates accurate 3 D face shapes by utilizing a deep neural network .
In addition to facial landmark fitting , we propose to align contours and the SIFT feature point pairs to extend the fitting beyond facial landmarks .
Our method is able to leverage from utilizing multiple datasets with different land -.
The log plot of the number of matched SIFT points in the 300W - LP training set .
It shows that the SIFT constraints cover the whole face , especially the highly textured area .
mark markups and numbers of landmarks .
We achieve the state - of - the - art performance on three challenging large pose datasets and competitive performance on hard medium pose datasets .
