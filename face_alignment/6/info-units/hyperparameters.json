{
  "has" : {
    "Hyperparameters" : {
      "use" : {
        "Adam stochastic optimization" : {
          "with" : "? 1 = 0.9 , ? 2 = 0.999 and = 1 e ? 8",
          "from sentence" : "We use Adam stochastic optimization with ? 1 = 0.9 , ? 2 = 0.999 and = 1 e ? 8 parameters ."
        }
      },
      "has" : {
        "train" : {
          "until" : "convergence",
          "with" : {
            "initial learning rate" : {
              "has" : "0.001"
            },
            "from sentence" : "We train until convergence with an initial learning rate ? = 0.001 ."          
          },
          "has" : {
            "coarse - to - fine ERT" : {
              "with" : "Gradient Boosting algorithm",
              "from sentence" : "We train the coarse - to - fine ERT with the Gradient Boosting algorithm ) ."
            }
          }
        },        
        "All layers" : {
          "contain" : {
            "68 filters" : {
              "to describe" : "required landmark features",
              "from sentence" : "All layers contain 68 filters to describe the required landmark features ."
            }
          }
        },
        "validation error" : {
          "has" : {
            "levels out" : {
              "for" : "10 epochs"
            }
          }
        },
        "depth" : {
          "of" : "trees",
          "set to" : "4",
          "from sentence" : "The depth of trees is set to 4 ."          
        },
        "number" : {
          "of" : {
            "tests" : {
              "to choose" : "best split parameters",
              "set to" : "200",
              "from sentence" : "The number of tests to choose the best split parameters , ? , is set to 200 ."
            }
          }
        }
      },
      "multiply" : {
        "learning rate" : {
          "by" : "decay = 0.05"
        },
        "from sentence" : "When validation error levels out for 10 epochs , we multiply the learning rate by decay = 0.05 ."
      },
      "apply" : {
        "batch normalization" : {
          "after" : "each convolution",
          "from sentence" : "We apply batch normalization after each convolution ."
        },
        "Gaussian filter" : {
          "with" : {
            "? = 33" : {
              "to" : "output probability maps"
            }
          },
          "to stabilize" : "initialization , g 0",
          "from sentence" : "We apply a Gaussian filter with ? = 33 to the output probability maps to stabilize the initialization , g 0 ."
        }
      },
      "requires" : {
        "maximum" : {
          "of" : {
            "T = 20 stages" : {
              "of" : {
                "K = 50 regression trees" : {
                  "per" : "stage"
                }
              },
              "from sentence" : "It requires a maximum of T = 20 stages of K = 50 regression trees per stage ."
            }
          }
        }
      },
      "resize" : {
        "each image" : {
          "to set" : {
            "face size" : {
              "to" : "160160 pixels"
            }
          },
          "from sentence" : "We resize each image to set the face size to 160160 pixels ."
        }
      },
      "generate" : {
        "Z = 25 initializations" : {
          "in" : {
            "robust soft POSIT scheme" : {
              "of" : "g 0"
            }
          },
          "from sentence" : "We generate Z = 25 initializations in the robust soft POSIT scheme of g 0 ."
        }
      },
      "augment" : {
        "shapes" : {
          "of" : "each face training image",
          "to create" : {
            "set , SA" : {
              "of" : {
                "at least N A = 60000 samples" : {
                  "to train" : "cascade"
                }
              }
            }
          },
          "from sentence" : "We augment the shapes of each face training image to create a set , SA , of at least N A = 60000 samples to train the cascade ."
        }
      },
      "To avoid" : {
        "overfitting" : {
          "use" : {
            "shrinkage factor" : {
              "has" : "0.1"
            },
            "subsampling factor" : {
              "has" : "0.5"
            }
          },
          "from sentence" : "To avoid overfitting we use a shrinkage factor ? = 0.1 and subsampling factor ? = 0.5 in the ERT ."
        }
      },
      "using" : ["NVidia GeForce GTX 1080 Ti ( 11 GB ) GPU", {"dual Intel Xeon Silver 4114 CPU" : {"at" : "2.20 GHz", "has" : ["210 cores", "20 threads", "128 GB of RAM"], "with" : {"batch size" : {"of" : "32 images"}}}}, {"from sentence" : "Training the CNN and the coarse - to - fine ensemble of trees takes 48 hours using a NVidia GeForce GTX 1080 Ti ( 11 GB ) GPU and an dual Intel Xeon Silver 4114 CPU at 2.20 GHz ( 210 cores / 20 threads , 128 GB of RAM ) with a batch size of 32 images ."}]
    }
  }
}