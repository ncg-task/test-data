156	3	10	utilize
156	15	68	300D Glo Ve 840B vectors ( Pennington et al. , 2014 )
156	69	71	as
156	72	103	our pre-trained word embeddings
159	3	6	use
159	7	33	Adadelta ( Zeiler , 2012 )
159	34	45	to optimize
159	46	74	all the trainable parameters
160	19	21	of
160	22	30	Adadelta
160	34	40	set as
160	73	80	1 e ? 6
161	0	8	To avoid
161	13	39	gradient explosion problem
161	45	50	apply
161	51	73	gradient norm clipping
162	4	14	batch size
162	18	24	set to
162	25	28	128
23	19	30	incorporate
23	31	49	positioninvariance
23	50	54	into
23	55	58	RNN
23	63	70	propose
23	73	84	novel model
23	85	90	named
23	91	137	Disconnected Recurrent Neural Network ( DRNN )
27	3	11	maintain
27	16	37	position - invariance
27	43	50	utilize
27	51	62	max pooling
27	63	73	to extract
27	78	99	important information
28	0	18	Our proposed model
28	31	42	regarded as
28	45	59	special 1D CNN
28	60	65	where
28	66	85	convolution kernels
28	90	103	replaced with
28	104	119	recurrent units
2	43	62	Text Categorization
172	7	15	see that
172	16	39	very deep CNN ( VDCNN )
172	40	48	performs
172	49	53	well
172	54	56	in
172	57	71	large datasets
180	0	5	shows
180	11	20	our model
180	21	29	achieves
180	30	64	10 - 50 % relative error reduction
180	65	78	compared with
180	79	90	char - CRNN
186	11	15	DRNN
186	16	24	performs
186	25	35	far better
186	36	40	than
186	41	44	CNN
193	0	14	Our model DRNN
193	15	23	achieves
193	24	47	much better performance
193	48	52	than
193	53	65	GRU and LSTM
