236	19	26	compare
236	27	80	three conventional document classification approaches
236	83	93	nave Bayes
236	98	117	two versions of SVM
236	124	136	stacking SVM
236	137	141	with
236	142	172	three deep learning approaches
236	175	178	DNN
236	181	184	RNN
236	191	194	CNN
231	36	41	using
231	59	92	central processing units ( CPUs )
231	97	132	graphical processing units ( GPUs )
232	19	26	done on
232	29	55	Xeon E5 ? 2640 ( 2.6 GHz )
232	56	60	with
232	61	69	32 cores
232	74	85	64GB memory
232	96	105	GPU cards
232	106	110	were
232	111	130	N vidia Quadro K620
232	135	153	N vidia Tesla K20c
233	3	14	implemented
233	15	29	our approaches
233	30	32	in
233	33	39	Python
233	40	45	using
233	50	94	Compute Unified Device Architecture ( CUDA )
233	103	105	is
233	108	187	parallel computing platform and Application Programming Interface ( API ) model
233	188	198	created by
233	199	206	N vidia
234	8	12	used
234	13	44	Keras and Tensor Flow libraries
234	45	57	for creating
234	62	77	neural networks
24	11	19	presents
24	22	34	new approach
24	35	37	to
24	38	74	hierarchical document classification
24	83	87	call
24	88	149	Hierarchical Deep Learning for Text classification ( HDLTex )
25	0	6	HDLTex
25	7	15	combines
25	16	43	deep learning architectures
25	44	52	to allow
25	58	91	over all and specialized learning
25	92	94	by
25	95	100	level
25	101	103	of
25	108	126	document hierarchy
2	40	59	Text Classification
5	51	74	document classification
9	19	46	hierarchical classification
237	25	28	RNN
237	29	40	outperforms
237	45	51	others
237	52	55	for
237	56	80	all three W OS data sets
238	0	3	CNN
238	4	12	performs
238	13	23	secondbest
238	24	27	for
238	28	43	three data sets
239	0	23	SVM with term weighting
239	24	26	is
239	27	32	third
239	33	36	for
239	41	55	first two sets
242	10	20	nave Bayes
242	21	25	does
242	26	36	much worse
242	37	41	than
242	46	59	other methods
243	73	90	HDLTex approaches
243	91	95	with
243	96	133	stacked , deep learning architectures
243	142	149	provide
243	150	170	superior performance
244	0	3	For
244	4	25	data set W OS ? 11967
244	32	45	best accuracy
244	49	60	obtained by
244	77	80	RNN
244	81	84	for
244	89	118	first level of classification
244	123	126	DNN
244	127	130	for
244	135	147	second level
245	5	10	gives
245	11	21	accuracies
245	22	24	of
245	25	29	94 %
245	30	33	for
245	38	49	first level
245	52	56	92 %
245	57	60	for
245	65	77	second level
245	82	86	86 %
245	87	95	over all
247	4	25	data set W OS ? 46985
247	30	41	best scores
247	52	63	achieved by
247	64	67	RNN
247	68	71	for
247	72	81	level one
247	109	116	level 2
