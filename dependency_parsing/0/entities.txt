9	63	101	https://github.com/datquocnguyen/jPTDP
75	4	15	jPTDP v 2.0
75	19	36	implemented using
75	37	47	DYNET v2.0
75	48	52	with
75	55	72	fixed random seed
77	0	15	Word embeddings
77	20	31	initialized
77	39	47	randomly
77	54	78	pre-trained word vectors
77	87	119	character and POS tag embeddings
77	124	144	randomly initialized
79	3	8	apply
79	9	16	dropout
79	17	21	with
79	24	45	67 % keep probability
79	46	48	to
79	53	59	inputs
79	60	62	of
79	63	70	BiLSTMs
79	75	79	MLPs
80	30	42	word dropout
80	43	51	to learn
80	55	64	embedding
80	65	68	for
80	69	82	unknown words
82	3	11	optimize
82	16	30	objective loss
82	31	36	using
82	37	41	Adam
82	67	71	with
82	75	96	initial learning rate
82	97	99	at
82	100	105	0.001
82	110	125	no mini-batches
86	49	52	use
86	53	86	100 - dimensional word embeddings
86	89	126	50 - dimensional character embeddings
86	131	165	100 dimensional POS tag embeddings
87	8	11	fix
87	16	38	number of hidden nodes
87	39	41	in
87	42	46	MLPs
87	47	49	at
87	50	53	100
18	19	26	present
18	29	63	novel neural network - based model
18	64	67	for
18	68	84	jointly learning
18	85	118	POS tagging and dependency paring
19	4	15	joint model
19	16	23	extends
19	28	77	well - known BIST graph - based dependency parser
19	78	82	with
19	86	143	additional lower - level BiLSTM - based tagging component
2	37	77	joint POS tagging and dependency parsing
4	44	107	joint part - of - speech ( POS ) tagging and dependency parsing
11	0	18	Dependency parsing
99	10	19	our model
99	20	28	produces
99	29	61	very competitive parsing results
100	26	33	obtains
100	36	45	UAS score
100	46	48	at
100	49	56	94.51 %
100	63	72	LAS score
100	73	75	at
100	76	83	92.87 %
102	3	10	achieve
102	11	37	0.9 % lower parsing scores
102	38	42	than
102	47	87	state - of - the - art dependency parser
106	8	14	obtain
106	17	60	state - of - the - art POS tagging accuracy
106	61	63	at
106	64	71	97.97 %
106	72	74	on
106	79	83	test
